{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "11b17607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: matplotlib in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: torchinfo in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: torchviz in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: filelock in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: graphviz in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from torchviz) (0.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\dev\\cs325\\cs325\\hw2\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision matplotlib torchinfo torchviz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(45)\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a4fa281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "91996770",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 1 ###\n",
    "\n",
    "class TitanicDataset(Dataset): \n",
    "    def __init__(self, DataFrame, Columns, categories, transformer, fit_transform=True, test=False):\n",
    "        df = self.one_hot_encode(DataFrame, Columns, categories)\n",
    "        df = self.scale(transformer, df, fit_transform)\n",
    "\n",
    "        if (test == True): \n",
    "            X = df.values\n",
    "            self.X = torch.tensor(X, dtype=torch.float32)\n",
    "            self.y = None\n",
    "            self.feats = df.columns.tolist()\n",
    "        else: \n",
    "            y = df[\"Survived\"].values\n",
    "            X = df.drop(columns=[\"Survived\"]).values\n",
    "\n",
    "            self.X = torch.tensor(X, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y, dtype=torch.float32)\n",
    "            self.feats = df.columns.tolist()\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.X) \n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        if (self.y is not None):\n",
    "            return self.X[idx], self.y[idx]\n",
    "\n",
    "        return self.X[idx]           \n",
    "\n",
    "    def one_hot_encode(self, DataFrame, Columns, categories): \n",
    "        df = DataFrame.copy() #create a copy to preserve original df\n",
    "\n",
    "        column_names = []\n",
    "        # loop through provided columns and convert indices to column names for use\n",
    "        for i in Columns: \n",
    "            if (isinstance(i, int)): \n",
    "                column_names.append(df.columns[i])\n",
    "            else: \n",
    "                column_names.append(i)\n",
    "\n",
    "        # loop through all columns \n",
    "        for col in column_names: \n",
    "            # get all categories within the column \n",
    "            values = categories[col]\n",
    "\n",
    "            # for all but the first category (ie. drop the first category)\n",
    "            for val in values[1:]:\n",
    "                new_col_name = f\"{col}_{val}\" #create new name\n",
    "\n",
    "                # create a new column with the new title. Then we must assign each sample \n",
    "                # a value in this column. If the original categorical column's value for the sample is \n",
    "                # equal to the category we are building a column for this comparison will return\n",
    "                # true, converted to 1, otherwise it will return false, converted to 0. \n",
    "                df[new_col_name] = (df[col] == val).astype(np.float32)\n",
    "        \n",
    "            df = df.drop(columns = [col]) #drop the original categorical column\n",
    "    \n",
    "        all_column_names = df.columns.tolist()\n",
    "\n",
    "        #convert df to matrix and return \n",
    "        #numpy_mat = df.to_numpy(dtype=np.float32)\n",
    "        #return numpy_mat, all_column_names\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def scale(self, transformer, DataFrame, fit_transform=True): \n",
    "        df = DataFrame.copy()\n",
    "\n",
    "        if(fit_transform):\n",
    "            data = transformer.fit_transform(df)\n",
    "        else:\n",
    "            data = transformer.transform(df)\n",
    "\n",
    "        # Add normalized data to dataframe\n",
    "        for index, column in enumerate(transformer.get_feature_names_out()):\n",
    "            df[column] = data[:,index]\n",
    "        \n",
    "        # Return\n",
    "        return df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3eab9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "train_df_ori = pd.read_csv('train.csv')\n",
    "test_df_ori = pd.read_csv('test.csv')\n",
    "\n",
    "# Saving passenger id's for kaggle submission\n",
    "passenger_ids = test_df_ori[\"PassengerId\"]\n",
    "\n",
    "train_df = train_df_ori.copy()\n",
    "test_df = test_df_ori.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ce68f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_feats = ['PassengerId', 'Name', 'Cabin', 'Ticket'] \n",
    "train_df.drop(irrelevant_feats, axis=1, inplace=True)\n",
    "test_df.drop(irrelevant_feats, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b29bba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing - This step will fill in blank or missing values in the dataset\n",
    "\n",
    "numerical_feats = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "categorical_feats = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "# We will replace missing numerical values with the median for that feature\n",
    "num_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# We will replace missing categorical values with the mode for that feature \n",
    "cat_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "# For every column other than \"Survived\", search for missing values\n",
    "# and replace them using the corresponding imputer \n",
    "for column in train_df.columns[1:]: \n",
    "    if (column in numerical_feats): \n",
    "        fill = num_imputer.fit_transform(train_df[column].values.reshape(-1,1))\n",
    "        train_df[column] = fill.ravel()\n",
    "        fill = num_imputer.transform(test_df[column].values.reshape(-1,1))\n",
    "        test_df[column] = fill.ravel()\n",
    "    else: \n",
    "        fill = cat_imputer.fit_transform(train_df[column].values.reshape(-1,1))\n",
    "        train_df[column] = fill.ravel()\n",
    "        fill = cat_imputer.transform(test_df[column].values.reshape(-1,1))\n",
    "        test_df[column] = fill.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c88cd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ColumnTransformer to apply specific normalization to each column in our data\n",
    "norm_scaler = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('minmax', MinMaxScaler(), ['Pclass', 'Parch']),  \n",
    "        ('standard', StandardScaler(), ['Age', 'SibSp', 'Fare'])\n",
    "    ], verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "46584b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(train_df, test_size=0.15, stratify = train_df['Survived'], random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ba347e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Survived  Pclass     Sex    Age  SibSp  Parch     Fare Embarked\n",
       "644         1     3.0  female   0.75    2.0    1.0  19.2583        C\n",
       "661         0     3.0    male  40.00    0.0    0.0   7.2250        C\n",
       "890         0     3.0    male  32.00    0.0    0.0   7.7500        Q\n",
       "109         1     3.0  female  28.00    1.0    0.0  24.1500        Q\n",
       "838         1     3.0    male  32.00    0.0    0.0  56.4958        S\n",
       "..        ...     ...     ...    ...    ...    ...      ...      ...\n",
       "790         0     3.0    male  28.00    0.0    0.0   7.7500        Q\n",
       "368         1     3.0  female  28.00    0.0    0.0   7.7500        Q\n",
       "568         0     3.0    male  28.00    0.0    0.0   7.2292        C\n",
       "3           1     1.0  female  35.00    1.0    0.0  53.1000        S\n",
       "182         0     3.0    male   9.00    4.0    2.0  31.3875        S\n",
       "\n",
       "[757 rows x 8 columns]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ff4ad1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "# When using the custom dataset class we need to create a dictionary ordering \n",
    "# the categories for onehotencoding, otherwise the test, val, and training sets\n",
    "# may end up with different columns\n",
    "categories = {}\n",
    "for col in ['Sex', 'Embarked']:\n",
    "    categories[col] = train_df[col].unique().tolist()\n",
    "\n",
    "train_dataset = TitanicDataset(df_train, categorical_feats, categories, norm_scaler, True, False)\n",
    "val_dataset = TitanicDataset(df_val, categorical_feats, categories, norm_scaler, False, False)\n",
    "test_dataset = TitanicDataset(test_df, categorical_feats, categories, norm_scaler, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4074de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  757\n",
      "val:  134\n",
      "test:  418\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \", len(train_dataset))\n",
    "print(\"val: \", len(val_dataset))\n",
    "print(\"test: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4ff1c00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Embarked_C', 'Embarked_Q']\n",
      "tensor([ 1.0000, -2.2340,  1.3450,  0.2000, -0.2647,  1.0000,  1.0000,  0.0000])\n",
      "\n",
      " ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Embarked_C', 'Embarked_Q']\n",
      "tensor([ 1.0000,  2.3021, -0.4846,  0.0000, -0.4948,  0.0000,  0.0000,  0.0000])\n",
      "\n",
      " ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Embarked_C', 'Embarked_Q']\n",
      "tensor([ 1.0000,  0.3943, -0.4846,  0.0000, -0.4837,  0.0000,  0.0000,  1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.feats)\n",
    "print(train_dataset.X[0])\n",
    "\n",
    "print(\"\\n\", val_dataset.feats)\n",
    "print(val_dataset.X[0])\n",
    "\n",
    "print(\"\\n\", test_dataset.feats)\n",
    "print(test_dataset.X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "eaf5a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6a8c86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2\n",
    "\n",
    "class MLP_Network(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size, num_classes, network_depth, learning_rate, regularization): \n",
    "        super(MLP_Network, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential()\n",
    "\n",
    "        in_size = input_size\n",
    "        out_size = hidden_size\n",
    "        for layer in range(network_depth): \n",
    "            self.model.add_module(f\"layer_{layer}\", nn.Linear(in_size, out_size))\n",
    "            self.model.add_module(f\"activation_{layer}\", nn.ReLU())\n",
    "\n",
    "            in_size = out_size\n",
    "            out_size = max(1, out_size//2)\n",
    "\n",
    "        self.model.add_module(f\"output_layer\", nn.Linear(in_size, num_classes))\n",
    "        #self.model.add_module(f\"output_activation\", nn.ReLU())\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(params=self.model.parameters(), lr=learning_rate, weight_decay = regularization)\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.model(x)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "884bcbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_Network(\n",
      "  (model): Sequential(\n",
      "    (layer_0): Linear(in_features=8, out_features=16, bias=True)\n",
      "    (activation_0): ReLU()\n",
      "    (layer_1): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (activation_1): ReLU()\n",
      "    (layer_2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (activation_2): ReLU()\n",
      "    (output_layer): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      "  (loss): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP_Network(input_size=8, hidden_size=16, num_classes=2, network_depth=3, learning_rate=0.1, regularization=0.0)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0df2c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    # these variable primarily affect efficiency at fetching data\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7ff8ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, num_epochs, show=False): \n",
    "    final_val = 0.0\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "\n",
    "        # We will track loss and accuracy for each epoch \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # each epoch is broken into batches of 64 images\n",
    "        for inputs, labels in train_loader: \n",
    "            inputs, labels = inputs.to(device), labels.long().to(device)\n",
    "\n",
    "            model.optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = model.loss(outputs, labels)\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        if(show):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_loss} | Accuracy: {epoch_acc}\")\n",
    "\n",
    "        # Validation loop \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad(): \n",
    "            for inputs, labels in val_loader: \n",
    "                inputs, labels = inputs.to(device), labels.long().to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = model.loss(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += (preds == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_corrects / len(val_loader.dataset)\n",
    "        final_val = val_acc\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if(show):\n",
    "            print(f\"Validation Loss: {val_loss} | Accuracy: {val_acc}\")\n",
    "    \n",
    "    return final_val, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec52c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader): \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for inputs in test_loader: \n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, prediction = torch.max(outputs, 1)\n",
    "            prediction = prediction.numpy()\n",
    "\n",
    "            for sample in prediction: \n",
    "                predictions.append(sample)\n",
    "            \n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ef5443f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, train_losses, val_losses = train(model, train_loader, val_loader, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "179cc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283582089552238\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "054c00b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "751b1258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0]), tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]), tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "predictions = eval(x, test_loader)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "962cfe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b83778d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters depth:5 layer_size:32 lr:0.001 reg:0.001 gave accuracy of: (0.3805970149253731, [0.729723320218342, 0.7289001044855408, 0.7280969774864782, 0.727306084714761, 0.7265264261981456, 0.7257491783232796, 0.7249781440554711, 0.724228796902232, 0.7234713302893242, 0.7227315038167029, 0.7219963031999344, 0.7212733638176357, 0.7205624079609799, 0.7198637909744343, 0.7191812861390914, 0.7185014591034369, 0.7178290139101298, 0.7171643091318944, 0.7165144017382059, 0.7158623788126867, 0.7152251574448267, 0.7145901195596672, 0.7139695174942873, 0.7133612797313826, 0.7127516174410892, 0.7121564653779588, 0.7115677521912236, 0.7109819952216457, 0.7104099790517688, 0.7098469257039784, 0.7092905180772355, 0.7087420573165268, 0.7081924865078895, 0.7076582773988439, 0.7071232765007524, 0.7065956638227838, 0.7060767194081486, 0.7055672615018515, 0.7050671640443991, 0.7045736262473908, 0.7040782254312281, 0.7035936517161139, 0.7031187358431646, 0.7026484492905388, 0.7021808717965765, 0.7017217928068799, 0.7012652916983853, 0.7008213966966778, 0.7003765351863644, 0.6999323164141162], [0.73019977203056, 0.7293717007138836, 0.728560558005945, 0.7277581807392747, 0.7269576405411335, 0.7261682828860496, 0.7253941075125737, 0.7246173958280193, 0.723854361185387, 0.7231000741915916, 0.7223566690487648, 0.7216251714905696, 0.7209051402647104, 0.7202006071361143, 0.7195048332214355, 0.7188108999337723, 0.7181283609190984, 0.7174578344644006, 0.7167891023763969, 0.7161311391574233, 0.7154781845078539, 0.71483808400026, 0.7142094987541882, 0.7135811421408582, 0.7129686056677975, 0.7123573288988712, 0.7117571003401457, 0.7111666247026244, 0.7105850346052824, 0.7100104538362417, 0.7094445095133426, 0.7088781506267946, 0.7083244848607192, 0.7077756470708705, 0.7072317360052421, 0.706693723130582, 0.7061669079225454, 0.7056517565428321, 0.7051379146860607, 0.7046307974786901, 0.7041309369144155, 0.7036384788911734, 0.7031502839344651, 0.7026675539230233, 0.7021946631260773, 0.7017221086060823, 0.7012602918183626, 0.7008002400398254, 0.7003433348527596, 0.6998924541829238])\n",
      "Parameters depth:5 layer_size:16 lr:0.001 reg:0.001 gave accuracy of: (0.3805970149253731, [0.7397344417899572, 0.7388589741216783, 0.7379990726355045, 0.7371422371272209, 0.7363001556975995, 0.7354702923540395, 0.7346525656027397, 0.7338362323560677, 0.7330279597517994, 0.7322319012179558, 0.7314390270051742, 0.730654287369752, 0.729891749716498, 0.7291310120920209, 0.7283823615336198, 0.7276451921526003, 0.7269148972264369, 0.7261844486824902, 0.725470994312508, 0.7247699366850456, 0.7240757954797783, 0.7233902124621594, 0.7227114511449554, 0.7220404510296478, 0.7213726321646213, 0.7207178241982958, 0.7200755253335759, 0.7194305834713511, 0.7187963073760704, 0.7181720243105013, 0.7175608208818827, 0.7169538406431282, 0.7163465952148841, 0.7157507186836737, 0.7151588037747846, 0.7145758856240478, 0.7140078380841718, 0.7134339130696407, 0.7128719713445384, 0.7123119231889239, 0.7117633829816015, 0.7112218491152381, 0.710690422212432, 0.7101589450747995, 0.7096341430274782, 0.7091185645036685, 0.7086077090771069, 0.708105450656014, 0.707608317761944, 0.7071187580434932], [0.7403800709923701, 0.7394972203382805, 0.7386185170999214, 0.7377526377564045, 0.7369018410568806, 0.7360633914150408, 0.7352247914271568, 0.7343961276225189, 0.7335770726203918, 0.7327639122507466, 0.7319611871420447, 0.7311743444471217, 0.7303942486421385, 0.7296255844742504, 0.7288683679566454, 0.7281141112099833, 0.7273675648134146, 0.7266330585550906, 0.7259109135883958, 0.7251982261885458, 0.7244958450545126, 0.7237953436908438, 0.7231045596635164, 0.7224196097744044, 0.7217440453927908, 0.72108285818527, 0.7204206781600838, 0.7197697269382761, 0.7191251916671867, 0.7184957176891725, 0.717871647272537, 0.7172485100689219, 0.7166316126709553, 0.7160207504656777, 0.7154225119903906, 0.7148374203425735, 0.7142468281646273, 0.7136671863385101, 0.7130902747609722, 0.7125241783127856, 0.711966113368077, 0.7114144038798204, 0.7108714020074304, 0.710329881354944, 0.7097975593894276, 0.7092706739012875, 0.7087516322064755, 0.7082358767737204, 0.7077331115950399, 0.7072295510946814])\n",
      "Parameters depth:3 layer_size:32 lr:0.001 reg:0.0 gave accuracy of: (0.3805970149253731, [0.7437949075094145, 0.742673363443095, 0.741578976811947, 0.740483651939125, 0.739412986775528, 0.738349682195026, 0.7373153100397974, 0.7362933880901714, 0.7352892958818685, 0.7343092108024789, 0.7333213324748383, 0.7323494061453655, 0.7314022461363315, 0.730465941731492, 0.7295542586904851, 0.7286605478277924, 0.7277859907641594, 0.7269303490810066, 0.7260840090294338, 0.7252543141851338, 0.7244332430384748, 0.723632843365285, 0.7228468528197023, 0.7220709332544234, 0.7212979491982151, 0.7205360842821935, 0.719780644227208, 0.7190418010343806, 0.7183126230850875, 0.7175983659027432, 0.7168941923775163, 0.7162029382574668, 0.7155236575058619, 0.7148488436381442, 0.7141872636550641, 0.7135313563491741, 0.7128861745723487, 0.7122497014514364, 0.7116173861678714, 0.710999638983879, 0.7103881376895124, 0.7097809934395622, 0.7091921727754953, 0.7086002458196965, 0.7080230344396916, 0.7074508552822129, 0.7068863448882512, 0.706323788219588, 0.7057730467347835, 0.7052300105479151], [0.7436571299140133, 0.7425504913970605, 0.7414533940713797, 0.7403772758014167, 0.7393053894612327, 0.7382571439244854, 0.7372211876200206, 0.7362074851989746, 0.7352105227868948, 0.7342103354966463, 0.7332256338489589, 0.7322569178111518, 0.7312997962111858, 0.7303760060623511, 0.7294694478832074, 0.7285753960040078, 0.727706797976992, 0.7268392710543391, 0.7259906005503526, 0.7251500487327576, 0.7243258481595054, 0.7235222067405929, 0.7227246788010668, 0.7219370665834911, 0.7211542876798716, 0.7203809716808263, 0.7196238476838639, 0.7188751021427895, 0.7181400861313094, 0.7174151575387414, 0.7167009213077489, 0.7160037996164009, 0.71530468517275, 0.7146260960778194, 0.7139508537392119, 0.7132822150614724, 0.7126252900308637, 0.7119719377204553, 0.7113325453516263, 0.7106994239252005, 0.7100733242817779, 0.709469158258011, 0.7088596367124301, 0.7082642930657116, 0.7076721751867835, 0.7070906980713801, 0.7065099700173335, 0.7059408586416671, 0.705380198670857, 0.7048224975813681])\n",
      "Parameters depth:3 layer_size:16 lr:0.001 reg:0.0 gave accuracy of: (0.3805970149253731, [0.8116353071507564, 0.8097299864144117, 0.8078428882431322, 0.8059811406280437, 0.8041370129963208, 0.8023250443144865, 0.8005295371442364, 0.7987575846745127, 0.7969928423983575, 0.795263291822557, 0.7935584544978022, 0.7918727896330063, 0.7901998247306602, 0.7885569739530707, 0.7869249146082284, 0.7853182476294402, 0.7837397718366576, 0.7821882677361703, 0.7806583676029543, 0.7791447541042867, 0.7776460905056176, 0.776156414688972, 0.7747013331876879, 0.7732448037738372, 0.7718190601196441, 0.7704119464207829, 0.7690206818095602, 0.7676433226391378, 0.7662866720277693, 0.764951417200474, 0.7636424762884566, 0.7623437712340563, 0.7610557939921219, 0.7597868113410677, 0.7585360715694756, 0.7573039153765498, 0.7560794130656647, 0.7548698049870318, 0.7536836134237846, 0.7525193682592485, 0.7513670067806067, 0.7502259269573257, 0.7490974419025638, 0.7479909204901288, 0.7468933336328484, 0.7458137310795299, 0.7447477413767081, 0.743693147971734, 0.7426678191875372, 0.7416211873725982], [0.8132838277674433, 0.8113548035052285, 0.8094463704237297, 0.8075600800229542, 0.8057054645979582, 0.8038719367625108, 0.8020536926255297, 0.8002506627965329, 0.7984806005634478, 0.7967366985420683, 0.7950111814399263, 0.7932977035864076, 0.791613702453784, 0.789941709433029, 0.7882985632811019, 0.7866778738463103, 0.785088753522332, 0.783521621084925, 0.7819723718201936, 0.7804356119525966, 0.7789077554176103, 0.7774151047663902, 0.775924585648437, 0.7744629418672021, 0.773021777174366, 0.7715936605610064, 0.7701804522258132, 0.7687886499646884, 0.7674197047504027, 0.7660700874542122, 0.7647412259187272, 0.7634238173712545, 0.7621203144984459, 0.7608350506469385, 0.7595695444007418, 0.7583088563449347, 0.7570709959784551, 0.7558503791467467, 0.7546565505995679, 0.7534715737869491, 0.7522987394190547, 0.7511396897372915, 0.7500030131482366, 0.7488730603189611, 0.7477664903028688, 0.7466713706059243, 0.7455842806332147, 0.7445246772979622, 0.7434545871037156, 0.7424016986320268])\n",
      "Parameters depth:5 layer_size:16 lr:0.001 reg:0.0 gave accuracy of: (0.3805970149253731, [0.8946007462599791, 0.8907892330004643, 0.8870424893604717, 0.8833513232329405, 0.8797491462888932, 0.876219124979828, 0.8727360261478702, 0.8693179563770521, 0.8659658341458168, 0.8626755553161137, 0.8594360908239962, 0.8562674573579584, 0.8531609627183236, 0.8501154341029995, 0.847111730153526, 0.844168647119832, 0.8412767712474657, 0.8384273015996109, 0.8356528911281923, 0.8329034184685157, 0.830208538702961, 0.8275787142182909, 0.8249906119613698, 0.8224421938785316, 0.8199462448904977, 0.8174761796722009, 0.8150471309532105, 0.812678505675166, 0.8103548632430274, 0.8080552477817712, 0.8058081169266996, 0.8036048478462895, 0.8014338216504459, 0.7993045703580547, 0.7972163693435599, 0.795161659919129, 0.7931391608604824, 0.7911581329341923, 0.789195505756998, 0.7872652792552661, 0.7853784813118737, 0.7835164847273178, 0.7816920200143812, 0.7799088887998261, 0.7781575413487232, 0.7764397581628323, 0.7747427768404922, 0.7730705486893497, 0.7714363676711149, 0.7698280675880502], [0.8952845477346164, 0.8914652635802084, 0.8877038332953382, 0.8840280806840356, 0.8804326431075139, 0.8768784216980436, 0.8733931032579336, 0.8699743338485262, 0.8666153256572894, 0.8633153242851371, 0.8600754097326478, 0.8569113798995516, 0.8538048783345009, 0.850740003941664, 0.8477335848025421, 0.8447840934369102, 0.8418788669714287, 0.8390398559285633, 0.8362375880355266, 0.8334887668268004, 0.8308018650581588, 0.8281599336595677, 0.8255597513113448, 0.8230078424980392, 0.8204859005871104, 0.818008505586368, 0.8155795958504748, 0.8132110878602782, 0.810866633457924, 0.8085701919313687, 0.8063159780715828, 0.8040989984327288, 0.8019224965750281, 0.7997905825501057, 0.7976885980634547, 0.7956201709918121, 0.7935985024295636, 0.7915916416182447, 0.7896190837248048, 0.7876823811388728, 0.7857806727067748, 0.7839197009357054, 0.7820926789027541, 0.7803029907283499, 0.7785372947578999, 0.7768071329415734, 0.7750980142337173, 0.7734255719540725, 0.7717792098201922, 0.7701445791258741])\n",
      "Parameters depth:3 layer_size:32 lr:0.01 reg:0.0 gave accuracy of: (0.6194029850746269, [0.6675643357134559, 0.6673826576066616, 0.6671897423314608, 0.6669856263435343, 0.6667854413488582, 0.6666001465707978, 0.6664405954088843, 0.6662598523942451, 0.666055789003284, 0.6659175180381008, 0.6656779594119033, 0.6655123740867706, 0.6653612498563064, 0.6651571598519107, 0.6650003858570064, 0.6647593457758663, 0.6646635451279039, 0.6644033051072528, 0.6642180412732154, 0.6640306976543865, 0.6638373693985227, 0.6636469505894609, 0.663439289503085, 0.6632541526733963, 0.6631145689887447, 0.6628622350478581, 0.6626538198091867, 0.6624573169957694, 0.6622221480902466, 0.662005774883487, 0.6618524333129944, 0.6616393649751318, 0.6613794001436927, 0.6611649201914688, 0.6608814592405543, 0.660707290846574, 0.6605002247043141, 0.6601942213082408, 0.6599315990702479, 0.6596740118106101, 0.6594132870790036, 0.6591306246886007, 0.6588521995034211, 0.6585650940079985, 0.6582717242770025, 0.6579599600959486, 0.6576440280778247, 0.6573311924304484, 0.6570121042007184, 0.6566639087474173], [0.6641860773314291, 0.6640426836796661, 0.6638923358561387, 0.663747446750527, 0.6636009278582103, 0.6634568927892998, 0.6633155497152414, 0.6631723295396833, 0.6630298548669957, 0.6628816376871137, 0.6627357904590777, 0.6625902376957794, 0.6624413008120522, 0.6622977763859194, 0.6621561601980409, 0.6620086671701119, 0.6618706530599452, 0.6617260379577751, 0.6615741368549973, 0.6614197439222194, 0.6612725684891886, 0.6611239821163576, 0.6609807165700998, 0.6608325536571332, 0.6606865000368943, 0.660537580055977, 0.6603844655093862, 0.6602292879303889, 0.6600710109098634, 0.6599100961614011, 0.6597459414112035, 0.6595777904809411, 0.6594077393190184, 0.6592327294064991, 0.6590553415355398, 0.6588772339607353, 0.6586941898758731, 0.6585042485550269, 0.6583062597175142, 0.6581018816179304, 0.6578929673379926, 0.6576767670574473, 0.6574541472676975, 0.6572218074727414, 0.6569795119228647, 0.6567322078035839, 0.6564782413084116, 0.6562150022876796, 0.6559456400017241, 0.6556687470692307])\n",
      "Parameters depth:5 layer_size:16 lr:0.01 reg:0.0 gave accuracy of: (0.6194029850746269, [0.6680212894078132, 0.6678458617574472, 0.6676516949421821, 0.667520391106448, 0.6673789938500881, 0.667244486166275, 0.6671425726171214, 0.667033398797049, 0.6669462290118834, 0.6668717391109844, 0.6668214418456608, 0.6667632704681891, 0.6666929088778981, 0.6666531996651401, 0.6666093652125551, 0.6665519573571975, 0.6665274357543753, 0.6664835476812315, 0.6664948509895345, 0.6664586749070545, 0.6664336553652976, 0.666385938658267, 0.6663965563163102, 0.6663849908892986, 0.6663335228690698, 0.6663153277835568, 0.6663208356621716, 0.6663124066047971, 0.666300013799176, 0.6662778573275557, 0.666287840042593, 0.6662647274557791, 0.6662937866491875, 0.6662556900688332, 0.6662697638514178, 0.6662435295402295, 0.6662535412308405, 0.6662351056008232, 0.6662304073060362, 0.6662231726249584, 0.6662303143952293, 0.6662455972781112, 0.666233193685388, 0.6662355707847616, 0.6662157196822223, 0.6662291133262049, 0.6662067776469605, 0.6662058801128181, 0.6662135859619202, 0.6662101129087148], [0.6656425541906215, 0.6654809588816628, 0.6653427890877226, 0.6652187438153508, 0.6651070625034731, 0.6650111524026785, 0.664932321256666, 0.6648556839174299, 0.6647911756785948, 0.6647377049745019, 0.6646850758524083, 0.6646476886165675, 0.6646066005550214, 0.6645698538467065, 0.6645396752143974, 0.6645106682136878, 0.6644883218096264, 0.6644684236441085, 0.6644497024479197, 0.6644345690954977, 0.6644224150856929, 0.6644113615377626, 0.6644019956019387, 0.6643920852177179, 0.664384683566307, 0.6643795406640466, 0.6643735704137318, 0.6643695653374515, 0.6643657283996468, 0.664363276602617, 0.6643610916920563, 0.6643590117568401, 0.6643575776868792, 0.66435650302403, 0.6643560502066541, 0.6643556881306777, 0.6643556347533838, 0.6643556810137051, 0.6643559363350939, 0.6643564567637088, 0.664357010997943, 0.6643583311963437, 0.6643595846731272, 0.6643603097147016, 0.6643613194351765, 0.6643617117582862, 0.6643632107706212, 0.664363570177733, 0.664365144807901, 0.6643654552858267])\n",
      "Parameters depth:3 layer_size:32 lr:0.001 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.6682631299391762, 0.6682317756913613, 0.6682106869066408, 0.6681788705456682, 0.6681531194494139, 0.6681225673053193, 0.6680984861627123, 0.6680757439593186, 0.6680491016279596, 0.6680184588564592, 0.6679924160360188, 0.6679681306471126, 0.6679427712722688, 0.6679138308157222, 0.6678916548170848, 0.6678656971911301, 0.6678378522159873, 0.6678116966427711, 0.6677874777874512, 0.6677629008318348, 0.6677382133281058, 0.6677111580948218, 0.6676873459211271, 0.6676605980808857, 0.6676354666524709, 0.6676091588000168, 0.6675853179657003, 0.6675595382088242, 0.6675343226095172, 0.6675162168128644, 0.6674853770389582, 0.6674627874297542, 0.6674378099340744, 0.667416257225223, 0.6673889023939559, 0.6673709358060376, 0.6673453701377072, 0.6673209026278719, 0.6672927342758783, 0.667270850237641, 0.6672498122389124, 0.6672230780990782, 0.667197099292609, 0.6671725827290171, 0.6671505948353947, 0.667133789553825, 0.6671044308411713, 0.6670803081249151, 0.6670540283031792, 0.6670316277438457], [0.667781816489661, 0.66775279169652, 0.6677238754372099, 0.6676955712375356, 0.6676678292786897, 0.6676400695274125, 0.6676131887222404, 0.6675860063353581, 0.6675591646735348, 0.6675316887115365, 0.6675043061598024, 0.667476775041267, 0.6674501789149954, 0.6674235578793198, 0.6673968096277607, 0.6673702161703536, 0.6673428309497549, 0.6673159519238259, 0.6672890177413598, 0.6672618914006362, 0.6672347552740752, 0.667208710713173, 0.6671824019346664, 0.6671560344411366, 0.667129774591816, 0.6671034311180684, 0.6670769924548134, 0.6670508740553215, 0.6670248908783073, 0.666998648821418, 0.6669732278852321, 0.6669478300792068, 0.6669227436407289, 0.6668972230669278, 0.6668722175840122, 0.66684687849301, 0.6668216603905407, 0.6667968070329126, 0.666771984812039, 0.6667475255567636, 0.6667223732862899, 0.6666974354146132, 0.6666724575099661, 0.6666478603633482, 0.6666230399217179, 0.6665987381294592, 0.6665744132070399, 0.6665500251214895, 0.6665256921924761, 0.6665012640739555])\n",
      "Parameters depth:5 layer_size:32 lr:0.01 reg:0.0 gave accuracy of: (0.6194029850746269, [0.6691628352811504, 0.6689552958449411, 0.6687681223001316, 0.6686955646290647, 0.6685524489164667, 0.6684272483758914, 0.6683316432343134, 0.6682328803851079, 0.6681742624058591, 0.6681159641027765, 0.6680318732872664, 0.6679438972252678, 0.6678718260761296, 0.6678642566011951, 0.6677630931099623, 0.6677441359983568, 0.6677249527512957, 0.6676611868047021, 0.6675898048490325, 0.6675202667004524, 0.6674863278787077, 0.6674525412574627, 0.6674423102028618, 0.6673722119123492, 0.6673928148837827, 0.6673864117544267, 0.6673309148696486, 0.667270656620968, 0.667245564719015, 0.6672190836430226, 0.6671831233813237, 0.6671605850305393, 0.6670968582167178, 0.6671086898568127, 0.6670294071755605, 0.6670745648985023, 0.6670395375242951, 0.6669866992271403, 0.6669263286981116, 0.6669487450050394, 0.6668839794798918, 0.6668836405916605, 0.6668376884025815, 0.6667982138289801, 0.6667990644352911, 0.6667579558912955, 0.6667431737819153, 0.6666868269207298, 0.6666612730630953, 0.6666302611679823], [0.6664423560028645, 0.6662655419378138, 0.6661237380397853, 0.6659980763250323, 0.6658877347832295, 0.6658013534190049, 0.6657024951123479, 0.6656228437352536, 0.6655448541712405, 0.6654904377994253, 0.6654400745434548, 0.6653967081610836, 0.6653601091299484, 0.6653250651573067, 0.6652877642147577, 0.6652631759643555, 0.6652368075812041, 0.6652056147803121, 0.6651768568736404, 0.665151220649036, 0.6651264518054564, 0.6651046035894707, 0.665085439361743, 0.6650650385600417, 0.6650462871167198, 0.6650292793316628, 0.6650208848625866, 0.6650040923659482, 0.6649892161141581, 0.6649766902425396, 0.6649627818990109, 0.6649475195514623, 0.6649352409946385, 0.6649229063916562, 0.6649097115246217, 0.6649024121796907, 0.6648918328000538, 0.6648794839631266, 0.6648643257013008, 0.6648538068159303, 0.6648389092132226, 0.6648289098668454, 0.6648152942088112, 0.6648004401975603, 0.6647877150507115, 0.6647727213688751, 0.6647566672581345, 0.6647426245817497, 0.6647308184139764, 0.6647133578115435])\n",
      "Parameters depth:5 layer_size:32 lr:0.1 reg:0.0 gave accuracy of: (0.6194029850746269, [0.6697576457789584, 0.6672166695368023, 0.6668274698673182, 0.666527813302951, 0.6667993053734854, 0.6669227902923897, 0.66673332570881, 0.6667123674716471, 0.6667879369488795, 0.6664584687710439, 0.6665224062089403, 0.6664038971361742, 0.6662603258456705, 0.6664536641012567, 0.6661527411153484, 0.6663014944667388, 0.6666433126954768, 0.6662950338586633, 0.6662913056156909, 0.6658563598931387, 0.6662096816608424, 0.6657978455330611, 0.665686323431713, 0.6656604737555177, 0.6659972206289576, 0.6655062052816192, 0.665284115855571, 0.6653555052913479, 0.6651212150228544, 0.6652167654415417, 0.6649101451334581, 0.6648184362616848, 0.6647329226510212, 0.6646479891817353, 0.6639539864765606, 0.6639588897262886, 0.6633329242664725, 0.6632145695988694, 0.6628001254332427, 0.6622410901628996, 0.6616592589898658, 0.6610264532474734, 0.6601470490742863, 0.6595688408715564, 0.6584562048256949, 0.6568225472574978, 0.6550605141187439, 0.6529893247580434, 0.6506612270952373, 0.6471038327664334], [0.6653176990907583, 0.6646868043871068, 0.6643968082186001, 0.664229474850555, 0.664201584324908, 0.6641704884927664, 0.6641005766925527, 0.6641294102170574, 0.6640411446343607, 0.6639943131759986, 0.6639710388966461, 0.6639239245386266, 0.6639699580064461, 0.6639046144129624, 0.6639354762746327, 0.6638081109345849, 0.6637293322762446, 0.663711693749499, 0.6637176782337587, 0.663717891742934, 0.6635939950373635, 0.663483836757603, 0.6635234311445436, 0.6633380135493492, 0.6632746057723885, 0.6631816954755071, 0.6631026828466956, 0.6629941249961284, 0.662910005049919, 0.6628042343837112, 0.6627709732126834, 0.6625866614170929, 0.6624105537115638, 0.6621643545022652, 0.6619449845000879, 0.6616666343674731, 0.66145874671082, 0.6610500385512167, 0.6607263648687903, 0.6602415958447243, 0.6597111038307646, 0.6590114707377419, 0.6582595447995769, 0.6572275410837202, 0.6562154720078653, 0.6545264436237848, 0.6527616310475478, 0.6503467195069612, 0.6473515781004038, 0.6435914617865833])\n",
      "Parameters depth:5 layer_size:16 lr:0.1 reg:0.0 gave accuracy of: (0.6194029850746269, [0.6705148342893492, 0.6674298693670779, 0.6665322386131891, 0.6666693554371792, 0.6664238368189319, 0.6666710038953603, 0.6663675813725319, 0.6664533876522372, 0.6662796560965252, 0.6663925204440814, 0.6663609755716362, 0.6664268097285393, 0.6665908108456762, 0.6665664009720362, 0.6663450582969142, 0.6665158473358759, 0.6663952295814827, 0.6667332101214672, 0.6663613177668624, 0.6666274922684603, 0.6666436455996222, 0.6664636276829667, 0.6667438734475342, 0.6665842503978523, 0.6665625114736973, 0.6662726094417244, 0.6664728456948203, 0.666451250703678, 0.6666856168755767, 0.6668248880492177, 0.6663713792986095, 0.666497480837798, 0.6665636987635765, 0.6663748055027214, 0.6663698971350253, 0.6666988451698183, 0.6664162501003814, 0.6668615840385266, 0.6663272291067569, 0.6663740397759441, 0.6664314758194957, 0.6663983479201242, 0.6666150622985164, 0.6666829892319763, 0.6664271923163451, 0.6664020531716088, 0.6663947048716375, 0.6666680234269076, 0.6667847775090165, 0.6665577975100538], [0.666741118502261, 0.6649393207991301, 0.6647287269136799, 0.6645151643610713, 0.664433395684655, 0.6644317240857366, 0.664361081906219, 0.6643813314722545, 0.6643902730585923, 0.6644522894674273, 0.6644048468390508, 0.6644184607178417, 0.6644122591659204, 0.664418256104882, 0.6643914393524626, 0.6644401025416246, 0.6644191715254713, 0.6644099959686621, 0.6644263027319267, 0.6644403409602037, 0.6644402333159944, 0.6644393890651304, 0.664381004091519, 0.6643728667230748, 0.6643695190771303, 0.6643684799991437, 0.6643685938707039, 0.664365828037262, 0.66435650302403, 0.6643606335369509, 0.6643907837013701, 0.6643631645102999, 0.6643753265266987, 0.6644168015736253, 0.664371614135913, 0.6644687563625734, 0.6644509470284875, 0.6644415508455305, 0.6644619979075531, 0.6644175372906586, 0.6644720666444124, 0.6644146113253352, 0.6643617864864976, 0.664360196732763, 0.6643646163726921, 0.6643557397287283, 0.6643592225971506, 0.6643635897494075, 0.6643931874588355, 0.664408125984135])\n",
      "Parameters depth:3 layer_size:32 lr:0.001 reg:0.001 gave accuracy of: (0.6194029850746269, [0.6717242834747547, 0.6716358669525408, 0.6715482858402096, 0.6714614039998074, 0.6713739790248745, 0.6712858066691118, 0.6712003734499177, 0.6711191790894442, 0.6710332215540947, 0.6709482623374918, 0.6708685297474678, 0.6707857811781658, 0.6707084652927152, 0.6706302394325226, 0.6705519949114307, 0.6704748133529602, 0.6703982698870146, 0.6703248484603952, 0.6702549289050789, 0.6701802099554195, 0.6701085543065594, 0.6700362698562552, 0.6699649308915182, 0.6698955392743039, 0.6698284563331655, 0.6697603921594204, 0.6696909113320838, 0.6696263053300674, 0.6695635154193742, 0.6694954321910399, 0.6694284073585248, 0.6693650764392263, 0.669300893968761, 0.66924083878531, 0.6691832785719767, 0.6691201852838776, 0.669058348417597, 0.6689982666994495, 0.6689376747592437, 0.6688808020071435, 0.6688230219573924, 0.6687693438410287, 0.6687108893218097, 0.6686563159547048, 0.6686019059688916, 0.6685481593504922, 0.6684977249236214, 0.6684459010077594, 0.6683950523404181, 0.6683421834141922], [0.6709530193414261, 0.6708579481537662, 0.6707636055661671, 0.6706670700614132, 0.6705737532074771, 0.6704807112466044, 0.6703881585775916, 0.6702972018896644, 0.6702077557791525, 0.6701204999169307, 0.6700329291286753, 0.6699459837443793, 0.6698608629739107, 0.669775854295759, 0.6696934370852229, 0.6696110874859255, 0.6695289620712622, 0.6694490882887769, 0.6693713060065881, 0.6692927390781801, 0.6692138287558484, 0.6691361861442452, 0.669059875296123, 0.6689844709723743, 0.6689083353797002, 0.6688348366253412, 0.6687602774420781, 0.6686894439939243, 0.6686186870532249, 0.6685462229287447, 0.6684742925772026, 0.6684051333968319, 0.668335915501438, 0.668268502648197, 0.6682004145721891, 0.6681337632350067, 0.6680670184875602, 0.6680006989792212, 0.6679347273129136, 0.6678725205250641, 0.6678093289261433, 0.6677489449728781, 0.6676884560442683, 0.6676279795703604, 0.6675702128837357, 0.6675121152578894, 0.6674559116363525, 0.6673976645540836, 0.6673383899589083, 0.6672844433072788])\n",
      "Parameters depth:3 layer_size:16 lr:0.001 reg:0.001 gave accuracy of: (0.6194029850746269, [0.6724679348805779, 0.6723803326664701, 0.6723024930160301, 0.6722208560694162, 0.6721417270059472, 0.6720566823586448, 0.6719808276924778, 0.6719016206784166, 0.6718314753025967, 0.6717528169347241, 0.6716813115179145, 0.6716074762445144, 0.6715417337386107, 0.6714679864942634, 0.6713908812328878, 0.671322330773428, 0.6712534744169469, 0.6711906156892663, 0.6711195042772684, 0.6710567698768455, 0.6709906992698125, 0.6709300724486851, 0.6708669716804787, 0.6708037989457658, 0.6707456829998263, 0.6706893463745772, 0.6706314895553035, 0.6705682776878186, 0.6705165290454578, 0.6704669083755271, 0.6704118129756681, 0.670359486554069, 0.6703060917369283, 0.6702564906727527, 0.6702060837254341, 0.6701559239366095, 0.670103865696543, 0.6700537057502424, 0.670008619915069, 0.6699588838940095, 0.6699162042125213, 0.6698674621796199, 0.6698222558753494, 0.6697738264321966, 0.6697337435290237, 0.6696869048291185, 0.669643237301034, 0.6695970207885833, 0.6695524589546133, 0.6695099084033991], [0.6727361456671758, 0.6726640142611603, 0.6725952838783833, 0.6725255402166452, 0.6724548473286984, 0.6723873739811912, 0.6723213222489428, 0.6722558211924424, 0.6721914819817045, 0.67212904478187, 0.6720677418495292, 0.6720090223782098, 0.671945849461342, 0.6718851692640959, 0.671825488111866, 0.6717695736173374, 0.6717145594198313, 0.6716578264734638, 0.671603276658414, 0.6715490773542604, 0.6714974873101534, 0.6714442496869102, 0.671391883003178, 0.6713414209992138, 0.6712913886824651, 0.6712413963986866, 0.6711932563070041, 0.6711462460347076, 0.6711006280201585, 0.6710559049649025, 0.671012784118083, 0.6709679996789392, 0.6709259330336728, 0.670884572747928, 0.6708410177657853, 0.6707981460130037, 0.670755712843653, 0.6707146559188615, 0.6706753106259588, 0.6706355374250839, 0.6705969643236985, 0.670558756856776, 0.6705198688293571, 0.6704809736849656, 0.6704426425606457, 0.6704061307124237, 0.6703678022569685, 0.6703314968009493, 0.6702948719707887, 0.6702597523803142])\n",
      "Parameters depth:5 layer_size:16 lr:0.1 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.6807718374612625, 0.6698565112237413, 0.6673145076085271, 0.6666227368886436, 0.6665097311276899, 0.6666462000956466, 0.6666400692421978, 0.6664867695603062, 0.6670227988550496, 0.6665834296332326, 0.6667563332591693, 0.6663759008266494, 0.6664499753847463, 0.6665461489357438, 0.6667280366430195, 0.6662852154697736, 0.6665362711784232, 0.6666202663272973, 0.6666424803563752, 0.6667412505282121, 0.6664470583790989, 0.6664555566471508, 0.66651675683819, 0.6666827986073462, 0.6664276677362198, 0.6665335961345638, 0.6667028634047414, 0.6664499732588209, 0.6667006815755383, 0.6666985503748512, 0.6665080751106635, 0.6666045628261692, 0.6664322421761768, 0.666717312767452, 0.6665337066039384, 0.6665303933100782, 0.6668093672201845, 0.6664706509525898, 0.6668918665050673, 0.6668347354136811, 0.6664212714570674, 0.6664541836931337, 0.6666146925450002, 0.6662546188387247, 0.6666353303186172, 0.6663941268561854, 0.6662796519234127, 0.666558010575006, 0.6667440569857468, 0.6663897006798295], [0.671528676552559, 0.6662591366625544, 0.6648742360855217, 0.6645195243963554, 0.66441559257792, 0.6644690357037445, 0.6644258685966036, 0.6644133018023932, 0.6643738248454991, 0.6643582991699675, 0.6643847387228439, 0.6643617686940663, 0.6644073306624569, 0.664414895114614, 0.6644449349659592, 0.6643851159223869, 0.6643736620447529, 0.6643777703171345, 0.6644800590045417, 0.6644209712298949, 0.6643733017480196, 0.6643595117241589, 0.6643559229907705, 0.6643582635851049, 0.6643658698494754, 0.6644072630512181, 0.6643592359414742, 0.6643741113036427, 0.6643575082963972, 0.6643555938307919, 0.6643704069194509, 0.6643558064503456, 0.6643775434636358, 0.6643948047908385, 0.664370380230804, 0.6643579753477182, 0.6644020036085329, 0.6644436814891759, 0.6643822371070065, 0.6643556561043014, 0.6643660006238453, 0.6644374550278507, 0.6644275304096848, 0.6644012500990683, 0.6643813981938718, 0.6643933084473681, 0.6643762099209116, 0.6644110990994012, 0.6643687646780441, 0.6643691489945597])\n",
      "Parameters depth:3 layer_size:16 lr:0.01 reg:0.001 gave accuracy of: (0.6194029850746269, [0.6809805417470289, 0.67884284793307, 0.6770037170917859, 0.6753664023022671, 0.6739545440894295, 0.6727272453207321, 0.6715599790589497, 0.6705692713610247, 0.669753428730656, 0.6691247436612884, 0.668482434875584, 0.6680152206786243, 0.6676324272880151, 0.6672350115473709, 0.6669447322817743, 0.6667097600637055, 0.6664503910425003, 0.6662042698425534, 0.6659786138225893, 0.6658021948611563, 0.6655834182565404, 0.6653418348046558, 0.6651159046190733, 0.6649179289331524, 0.6647225732532486, 0.6645116982403331, 0.6643371978083249, 0.6641083767581017, 0.6639211777809274, 0.6636816037220873, 0.6635179405483261, 0.6632710944078715, 0.6630617840759347, 0.662884277506895, 0.6626394423342444, 0.6624245194809283, 0.6621972200420133, 0.6619028279771892, 0.6616753243707131, 0.6614385686588413, 0.661173080201193, 0.6609282064469362, 0.6606889371040475, 0.6604199821284457, 0.660131070856374, 0.6599096957412075, 0.659653340258403, 0.6593410606585847, 0.6590989345445973, 0.6588012281623196], [0.6821803824225469, 0.6800442729423295, 0.6781352411455183, 0.676527591783609, 0.675030195001346, 0.6736044848143165, 0.672275248748153, 0.6712003368050304, 0.6702414697675563, 0.6694609878668144, 0.6688044845168271, 0.6682068919067952, 0.6678036309000271, 0.6674816608428955, 0.6671905437512184, 0.6669372373552465, 0.6667229889044121, 0.6665224468530114, 0.6663206842408251, 0.666117564955754, 0.6659432569546486, 0.6657860492592427, 0.66563626723503, 0.6654901015224741, 0.6653724686423345, 0.6652499232719193, 0.6651396840365965, 0.6650211215019226, 0.6648633933779019, 0.6647011477555802, 0.6645464852674684, 0.6643824319341289, 0.6641992054768463, 0.6640199760892498, 0.6638289636640406, 0.6636236799297048, 0.6634521012875572, 0.6632456281291905, 0.6630324080808839, 0.6628184185099246, 0.6625890242519663, 0.662361120999749, 0.662111402447544, 0.6618649665989093, 0.6616100428709343, 0.661361952326191, 0.6611049344290548, 0.660845711160062, 0.6605796333569199, 0.6603100771334633])\n",
      "Parameters depth:5 layer_size:32 lr:0.001 reg:0.0 gave accuracy of: (0.6194029850746269, [0.6887595840142929, 0.6884516830330953, 0.6881487638033837, 0.6878525158845606, 0.6875573318732147, 0.6872597512354781, 0.6869668890494494, 0.6866771259112591, 0.686379611255943, 0.686101993213714, 0.6858279339703417, 0.6855514106221369, 0.6852823818690553, 0.685019067366813, 0.6847571703055418, 0.6844928913418808, 0.6842336888514863, 0.6839860017107532, 0.6837358905428153, 0.6834870376864072, 0.6832414902500621, 0.6830091648876588, 0.68277046899342, 0.6825324570172057, 0.6823023611992165, 0.6820734689698666, 0.6818418865002288, 0.6816199636837292, 0.6814045859611491, 0.6811789203351524, 0.6809631267973423, 0.6807570495252723, 0.6805493849744255, 0.6803470124814123, 0.6801499196056331, 0.6799514518861254, 0.6797509521757753, 0.6795609528826282, 0.6793648017917315, 0.6791735823749708, 0.6789889437204308, 0.6788008390991029, 0.6786138150777024, 0.6784281025947007, 0.6782536267289397, 0.6780814819795767, 0.6779020385351647, 0.6777310146995705, 0.6775602505418079, 0.6773950936299806], [0.6855389498062988, 0.6852479029947253, 0.6849598462012276, 0.684672242225106, 0.6843902673294295, 0.684106860587846, 0.6838249146048703, 0.6835429352610859, 0.6832724080156924, 0.6830069106906208, 0.6827439750308422, 0.6824811327813277, 0.6822273086256055, 0.6819730280940213, 0.6817223918971731, 0.6814751371518889, 0.6812343988845597, 0.6809948571582338, 0.6807572948398875, 0.6805222319133246, 0.6802961176900721, 0.6800686040920998, 0.6798428056845024, 0.6796205328471625, 0.6793999849860348, 0.6791822856931544, 0.6789718216924525, 0.6787627499494979, 0.6785499560299204, 0.6783434882092831, 0.678147428071321, 0.6779506144238941, 0.6777559750115694, 0.6775658815654356, 0.6773778351385202, 0.677189826965332, 0.6770057500298343, 0.6768217789593027, 0.6766400070332769, 0.6764603435103573, 0.6762818516190372, 0.6761057474719945, 0.675933140427319, 0.675764470847685, 0.6755984283205289, 0.6754317968638975, 0.67526862069742, 0.6751077539885222, 0.6749497047111169, 0.6747936624199596])\n",
      "Parameters depth:3 layer_size:32 lr:0.01 reg:0.001 gave accuracy of: (0.6194029850746269, [0.6909898525815029, 0.6868002928862326, 0.6833324494576045, 0.6803344747191848, 0.6778522670032798, 0.6756185279024797, 0.673682566048132, 0.6721383347379012, 0.6706872996597341, 0.6694570064072249, 0.6683433418072356, 0.6674518111989867, 0.6666349324556449, 0.6659246402026168, 0.6652625155889846, 0.6646722760666629, 0.6641729760673906, 0.6637251427498015, 0.6633050803936614, 0.6628996627491406, 0.662562763438987, 0.6622104705403629, 0.6618945464747743, 0.6616166310392251, 0.6613531255974008, 0.6610932996597442, 0.6608341120508262, 0.6606113243764427, 0.6603743835515988, 0.6601270819907145, 0.6598874366740097, 0.6596729823116267, 0.6594502152665918, 0.6592538464652028, 0.6589765771534515, 0.6587144900187161, 0.6585116027368422, 0.6582615355046926, 0.6580223593088248, 0.6577434732702954, 0.6574955362939772, 0.6572223881276784, 0.6569269208171093, 0.6566877869035326, 0.6563760578396141, 0.6560464606102423, 0.6557591023659297, 0.6554275805443093, 0.6550758177884504, 0.6547362954802368], [0.6870672604930934, 0.6833365239314179, 0.6801428225503039, 0.6774275445226413, 0.6750682085307677, 0.6730121311856739, 0.6713081215744587, 0.6698196334625358, 0.668500110284606, 0.6673306733814638, 0.6663701641025828, 0.6654887065958621, 0.6647412172004358, 0.6640587128810028, 0.6634487669859359, 0.662897374202956, 0.6624244033400692, 0.6619789849466352, 0.6615673259123048, 0.6611910515756749, 0.6608423297084979, 0.660520849832848, 0.6602177824547042, 0.6599460226386341, 0.6596755136304827, 0.6594234749452391, 0.6591765453566366, 0.6589340505315296, 0.6587069470490983, 0.6584773472885588, 0.6582502064420216, 0.6580266534392514, 0.6577990571064736, 0.6575698683510965, 0.6573338499709741, 0.6571017601596776, 0.6568683234613333, 0.6566327063005362, 0.6563887916394134, 0.6561400498916854, 0.655882436837723, 0.6556218818052492, 0.6553530203762339, 0.655077164742484, 0.6547895910134957, 0.6544975380399334, 0.6541880013337776, 0.6538668043577849, 0.6535388293550976, 0.653196986041852])\n",
      "Parameters depth:5 layer_size:32 lr:0.001 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.6949618398907005, 0.6943634483111897, 0.6937869080149198, 0.6932241633987175, 0.692665715828597, 0.6921217897451696, 0.6915882284921573, 0.691052311005334, 0.6905414830583247, 0.6900352201027158, 0.6895406859554104, 0.689053512548676, 0.6885733543015534, 0.6880914498824267, 0.6876411146657785, 0.6871905007167095, 0.6867441575939778, 0.6863206350189219, 0.6859000333076739, 0.6854913233135934, 0.6850866913165568, 0.6846954822540283, 0.6843095661154511, 0.6839240663432697, 0.6835503632515236, 0.6831962741822831, 0.6828378009827638, 0.6824865571888781, 0.6821440790571971, 0.6818107945285984, 0.6814832583443806, 0.6811548180120309, 0.6808374170583023, 0.6805268381986782, 0.6802168073553391, 0.6799214647657175, 0.6796260774529279, 0.6793410326877075, 0.6790593227905515, 0.6787827862143674, 0.6785081545459389, 0.6782417209176753, 0.6779800837704496, 0.6777325347361193, 0.6774848086200901, 0.6772428039987934, 0.6770042722732261, 0.6767700220036224, 0.6765433211307702, 0.6763177256603065], [0.6954041657163136, 0.6948009889517257, 0.6942130060338262, 0.6936293084229996, 0.6930625607718283, 0.6925039460409933, 0.6919465554294302, 0.6914080648279902, 0.6908787862578435, 0.6903580444962231, 0.6898500385569103, 0.689345833080918, 0.6888473505404458, 0.6883733459373018, 0.6879007700663894, 0.6874368840189122, 0.6869837695093297, 0.6865449174126582, 0.6861182006437387, 0.6856875455201562, 0.6852815587129166, 0.6848684318030058, 0.6844664376173446, 0.6840730193835586, 0.6836965769084532, 0.6833258253424915, 0.6829562756552625, 0.6825921473218434, 0.6822419371177901, 0.6818972995032125, 0.6815485313757143, 0.6812129527775209, 0.6808839173459295, 0.6805572340737528, 0.6802439707428661, 0.6799310935077383, 0.6796263216146782, 0.6793306541087022, 0.6790385272965502, 0.6787463791334807, 0.6784637143362814, 0.6781850261474723, 0.6779138445854187, 0.6776502639500063, 0.6773923902369258, 0.6771369932302788, 0.6768874499335218, 0.6766410238707243, 0.6764034984716728, 0.6761702254636964])\n",
      "Parameters depth:3 layer_size:32 lr:0.01 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.6972055765092766, 0.6927138411069641, 0.6888891244344069, 0.6856181784539116, 0.6827260492027515, 0.6802419250046089, 0.6779570017339689, 0.676083757981284, 0.6744703407174215, 0.6732263028070508, 0.6720044358560872, 0.6710142269632146, 0.6701637594671513, 0.6694116286116516, 0.66877146323102, 0.6681707137642008, 0.6676914218709837, 0.667245831325788, 0.6668540536963641, 0.6665113346264888, 0.666170661720291, 0.6658394001276678, 0.6655711408807863, 0.6653245767010093, 0.6650285979873123, 0.6648223564678328, 0.6645979789950573, 0.6643956246117777, 0.6641289961857714, 0.6639333205147495, 0.6637015165551965, 0.6634596853936522, 0.6632866651567789, 0.6630346882925954, 0.6627995511184753, 0.662567525905221, 0.6623689675583078, 0.6621577366497589, 0.6619247666595791, 0.6616896557839418, 0.6614904464314761, 0.6612199522859984, 0.66102234611738, 0.6608102330285933, 0.660519706132075, 0.6603153527491631, 0.6600831658868526, 0.6598525074073156, 0.6595837042385237, 0.6593781426214321], [0.6962124589663833, 0.6920882365596828, 0.6884951724934933, 0.6854238572405346, 0.6826980549897721, 0.6802911767319068, 0.6781119090407642, 0.6762543765466604, 0.6747194270589458, 0.6733803731292042, 0.6721982253131582, 0.6712147219857173, 0.6703633025510988, 0.6695995055027862, 0.6689132727793793, 0.668335629932916, 0.6678544540903462, 0.6674210197889983, 0.6670282429723597, 0.6666709166854176, 0.6663431204966644, 0.6660472732871326, 0.6657843536405421, 0.6655293969965693, 0.665304569166098, 0.6650778242011568, 0.6648793069284353, 0.6646853089332581, 0.6644916890272453, 0.6643012112645961, 0.6641167233239359, 0.6639295247063708, 0.6637635862649377, 0.6635934799464781, 0.6634217936601212, 0.6632463353783337, 0.663069841577046, 0.6628961100507138, 0.6627237930226682, 0.6625511859779927, 0.6623716647945234, 0.6621928010413896, 0.6620137789356175, 0.6618322018367141, 0.6616500811790352, 0.6614624039450688, 0.661263707858413, 0.6610645900911359, 0.6608619832280856, 0.6606609848008227])\n",
      "Parameters depth:5 layer_size:16 lr:0.01 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.7017184773083565, 0.6951838176663044, 0.6898808054911413, 0.6854685710317392, 0.6818403645739688, 0.6789185023685742, 0.6764779944400964, 0.6746015125883146, 0.6729700839346278, 0.6716417860795831, 0.6706807919663513, 0.6699234566883808, 0.6692107627697319, 0.668699441923018, 0.6682850927941235, 0.6679548986521864, 0.6677556958349724, 0.6675256775738856, 0.6673436668778978, 0.6671789986926624, 0.667130545628118, 0.667023233252441, 0.6669450372339397, 0.6668857270691795, 0.6668650575641597, 0.6668255558259578, 0.6667985215369745, 0.6667611383226463, 0.6666954329810653, 0.6666754033795436, 0.6667274976028634, 0.6666661834779787, 0.6667036560599051, 0.6666413122785612, 0.6666595124033042, 0.6666632934007178, 0.6666312371251447, 0.6666570695577241, 0.6666615505357084, 0.666628425392166, 0.6666093309615373, 0.6666373558529459, 0.6666641951867107, 0.6666357055050536, 0.6666065759986364, 0.666645134534672, 0.6665882443027421, 0.6665818067648924, 0.6665630777571916, 0.6665551514417681], [0.697965722475479, 0.6919562709865286, 0.6869769345468549, 0.6828870203957629, 0.6795242588911483, 0.6766876160208859, 0.6743960353865552, 0.6725732417248967, 0.6710000189382639, 0.6698164939880371, 0.6689146596993973, 0.6680909003784408, 0.667512805604223, 0.6669824559297135, 0.6665687142913022, 0.66622688432238, 0.6659817713410107, 0.6657392934187135, 0.6655434076465777, 0.6654111742973328, 0.6652947432959258, 0.6651829605671897, 0.6651166152598252, 0.6650579749648251, 0.6650114264061202, 0.664955253921338, 0.6649103235842576, 0.6648762475198774, 0.6648523140309462, 0.6648255061747422, 0.6648132418518635, 0.6647927947898409, 0.6647710310879038, 0.6647565569450606, 0.6647363447431308, 0.6647222958393951, 0.6647172205483736, 0.6647138542203761, 0.6647071945133494, 0.6646975839315955, 0.6646886405660145, 0.6646782898191196, 0.6646708872780871, 0.6646612215397963, 0.6646543767914843, 0.6646435563244036, 0.6646344208005649, 0.6646273349648091, 0.6646250246176079, 0.6646199804633411])\n",
      "Parameters depth:3 layer_size:16 lr:0.001 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.7018112539457676, 0.7013718352765042, 0.7009464600757059, 0.7005148745748452, 0.700089283238314, 0.6996638586688073, 0.6992520804921734, 0.6988396683173892, 0.6984312120170543, 0.6980361317233964, 0.6976437671023914, 0.6972554013467686, 0.6968712150026974, 0.6964952441786207, 0.6961245884826035, 0.6957579192113688, 0.6953941500958553, 0.6950408108483217, 0.6946793427713008, 0.6943310311007531, 0.6939830046978778, 0.6936429984660886, 0.6933047557286574, 0.6929709517656576, 0.6926468344629204, 0.6923210599620875, 0.6919941227376225, 0.6916735042354075, 0.691357512218949, 0.6910484993788494, 0.6907426218060553, 0.690440743728547, 0.6901468324377799, 0.6898507709704743, 0.6895640084576575, 0.6892758250393988, 0.6889895157423486, 0.688706299666527, 0.6884330175669379, 0.688159106193477, 0.6878869483933896, 0.6876205667321874, 0.6873625648383893, 0.6871044337355792, 0.68685306779932, 0.6865985525016584, 0.6863493587885696, 0.6861037742666398, 0.6858570560753897, 0.6856216017447185], [0.7009029183814774, 0.7004490717133479, 0.7000043329907887, 0.6995594421429421, 0.6991157318229106, 0.6986836897793101, 0.6982534136345138, 0.6978239701755011, 0.697410725835544, 0.6969991121719132, 0.6965869211438876, 0.6961852000720465, 0.6957976399962582, 0.6954077393261354, 0.6950180254765411, 0.6946419094925496, 0.6942642767037919, 0.6938910831266375, 0.6935216953505331, 0.6931567129804127, 0.6927973361157659, 0.6924432044598594, 0.6920908858526998, 0.6917489509084331, 0.6914025554016455, 0.6910647669834877, 0.690726846011717, 0.6903923127188611, 0.6900669950157848, 0.6897438862430516, 0.6894273998132393, 0.6891162715741058, 0.6888025687701667, 0.6884997140115766, 0.6881945133209229, 0.687892204789973, 0.687595909211173, 0.6873056506043049, 0.6870152051769086, 0.68672832535274, 0.6864450787430378, 0.6861725627486386, 0.6858967311346709, 0.6856297103326712, 0.6853620374380652, 0.6851006132453236, 0.6848359170244701, 0.6845775424544491, 0.6843249824509692, 0.6840735166820128])\n",
      "Parameters depth:5 layer_size:16 lr:0.01 reg:0.001 gave accuracy of: (0.6194029850746269, [0.7536440620019225, 0.7428188061777162, 0.7332475588532703, 0.7247653429542854, 0.7173991375744264, 0.7108367341355257, 0.7051102349748699, 0.7000471226762749, 0.6956050588873608, 0.6918044144600197, 0.6884811178853679, 0.68551991551209, 0.6829912666443002, 0.6807496820132357, 0.67874300826336, 0.6770408011805586, 0.6755743707816856, 0.6743348564465421, 0.6732076141919296, 0.6722892033061704, 0.6713942231086317, 0.6706788325719191, 0.670042928569068, 0.6695160241391573, 0.6690634618977102, 0.6686267521296341, 0.6682663672508935, 0.6679853881208553, 0.6676998722663486, 0.6674486804984835, 0.6672587289992853, 0.6671175874051204, 0.6669783100111797, 0.6668551566578753, 0.6667419206670915, 0.6666606215851153, 0.6665611388346321, 0.6664846614298449, 0.6664139847301901, 0.6664031684162437, 0.6662956739196374, 0.6662924448754073, 0.6662270388955956, 0.6662364239894257, 0.6662036370254728, 0.666180234919136, 0.6661198604532088, 0.6661225355758063, 0.6660901733244741, 0.6661076013446642], [0.748560342326093, 0.7381711442079117, 0.7290638000217836, 0.7210255167377528, 0.7139503279728676, 0.7077265283954677, 0.702177735406961, 0.6973104334589261, 0.6931542843135435, 0.6895000765572733, 0.686199294097388, 0.6834228759381309, 0.6809428440990732, 0.6787415947487105, 0.6768136549351821, 0.6751662679572603, 0.6737686698116473, 0.6725050424461934, 0.671431798543503, 0.6704619322250138, 0.6696147794154153, 0.6688988093119949, 0.6682734186969587, 0.6677177913153349, 0.6672196557272726, 0.666806147169711, 0.6664361704641314, 0.6661117530580777, 0.6658260244042126, 0.665574185883821, 0.6653607167414765, 0.6651887689063798, 0.6650451110370124, 0.6649069554770171, 0.6647745717817278, 0.6646739626998333, 0.664576948578678, 0.6644909132772417, 0.6644242121212518, 0.6643393110873094, 0.6642861481922776, 0.6642355981157787, 0.6641907238248569, 0.664143812300554, 0.6641044394293828, 0.6640724237285444, 0.6640472945882313, 0.6640264587615853, 0.6640018473810224, 0.6639816761016846])\n",
      "Parameters depth:5 layer_size:32 lr:0.1 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.7673527899160095, 0.6908586206335373, 0.6721756499226216, 0.667937662595172, 0.6668362793865733, 0.6664858767504421, 0.6665989313289385, 0.6663841131971251, 0.6663925587894737, 0.6665589566117391, 0.6664909611762436, 0.6662777815028887, 0.666256541698738, 0.6662003334163832, 0.6661689648382573, 0.6662366370543779, 0.6662122100158601, 0.6661969654783705, 0.6665625084816543, 0.6663789339708054, 0.6660933417404659, 0.6662314415292979, 0.6662573751401712, 0.6660555823161076, 0.6663589105108455, 0.6658615605361868, 0.666575326551062, 0.6660396588210858, 0.6658354104746286, 0.6659771209506409, 0.6661519879866465, 0.6658556780223015, 0.6660166789864926, 0.666349641949214, 0.6659924308406472, 0.6656907123650081, 0.6657471803251944, 0.6660630840763863, 0.666099617865473, 0.6658195121757577, 0.665456777362244, 0.6655901634236465, 0.6655673089399048, 0.665611586451058, 0.6652236783992661, 0.6657501320542873, 0.6655990333349261, 0.665328171876809, 0.6651093947997654, 0.6648016888525243], [0.7099901953739907, 0.6757824536579758, 0.6666559550299573, 0.6653608519639542, 0.6643985856824847, 0.6640105852440222, 0.6639918747232921, 0.6639600111477411, 0.6639558156924461, 0.6639331721547824, 0.6640010529489659, 0.6639632182334786, 0.6639608776391442, 0.6639808443055224, 0.6639233258233141, 0.6638915111769491, 0.663915565654413, 0.6638346172090787, 0.6639414580900278, 0.6639436332147512, 0.6638629285257254, 0.6638013151154589, 0.6637185358289462, 0.6636846110002318, 0.663670093265932, 0.6636598483840032, 0.663632514761455, 0.6635643012488066, 0.6635530146200266, 0.6634974488571509, 0.663460763532724, 0.6634691962555274, 0.6633952455734139, 0.6633794343293603, 0.6633200939021894, 0.6632444511598615, 0.6631911699451617, 0.6631715048604937, 0.6631228096449553, 0.6630157525859662, 0.6629372239112854, 0.6628666457845204, 0.6628118104009486, 0.662715341617812, 0.6626173204450465, 0.6625013484883664, 0.6625347075177662, 0.6624294946442789, 0.6621293754719976, 0.6619220856410354])\n",
      "Parameters depth:5 layer_size:32 lr:0.01 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.7994219022981399, 0.7725107616288501, 0.7513706864422505, 0.7336687156672207, 0.7191594293441924, 0.7075236351518367, 0.69805385312127, 0.6906210725027158, 0.6844968009971407, 0.6798660211865464, 0.6761862026180585, 0.6733865222181322, 0.6712740632942835, 0.6695922710779006, 0.6682913916744045, 0.6673776971931659, 0.6665712643803504, 0.6659738240342788, 0.6654853723953076, 0.6651777825865752, 0.6648917059602322, 0.6647419285427784, 0.664491897293882, 0.6643796588344649, 0.6642020095134821, 0.6641244710357848, 0.6640134143545889, 0.663961242101939, 0.6638353648084946, 0.6637523663248694, 0.6637434659419947, 0.6636734352874, 0.6636716834462618, 0.6635569509615828, 0.6635106935841246, 0.6634138806020567, 0.6633511340759862, 0.6633281266831029, 0.663262968727903, 0.6631951619485883, 0.6631880560828326, 0.6631031954461706, 0.6630408978840161, 0.6629678125897991, 0.6628790786748203, 0.6628218915219981, 0.6628418581331422, 0.6627173165506541, 0.6626436976492012, 0.6625461255543456], [0.7853389417947229, 0.7620483983808489, 0.742519171380285, 0.7263336030404959, 0.7132911032705165, 0.7026262923852721, 0.69403750860869, 0.687153111642866, 0.6818070064729719, 0.6775605981029681, 0.674252436232211, 0.671707070585507, 0.6697582308925799, 0.668242543490965, 0.6670660803567118, 0.6661172420231264, 0.6653953746183595, 0.6648022105444723, 0.664400186111678, 0.6640627917958729, 0.6637622553910782, 0.6635452909256095, 0.663375757523437, 0.66321032883516, 0.6630714998316409, 0.6629737820198287, 0.6628788869772384, 0.6627947714791369, 0.6627223669593014, 0.6626515041536359, 0.6625921139076575, 0.6625299738414252, 0.6624728076493562, 0.6624245020880628, 0.6623719637073687, 0.6623216075683708, 0.6622716028298905, 0.6622135737049046, 0.6621648046507764, 0.6621128721023674, 0.6620622757655471, 0.6620133519172668, 0.6619587985437307, 0.6619066800644149, 0.6618538285369304, 0.661801621095458, 0.6617507489759531, 0.6616949955029274, 0.6616392126723901, 0.6615807147168401])\n",
      "Parameters depth:5 layer_size:16 lr:0.1 reg:0.001 gave accuracy of: (0.6194029850746269, [0.8307490592903631, 0.7005767384482501, 0.6733190014151318, 0.6683181038463446, 0.6668517346268759, 0.6665324228600435, 0.6665527467841044, 0.6665027088816604, 0.6671194876673358, 0.6671623585246198, 0.6665256876926599, 0.6664343111738661, 0.6665867443443761, 0.6664102163308521, 0.6669287213876036, 0.6669808627749686, 0.6665225471499102, 0.6662675010008415, 0.6663064456678917, 0.6663153598299114, 0.6664490677721434, 0.6664493785509188, 0.6665089693378111, 0.666248628060128, 0.6661656952439715, 0.666439896924335, 0.6663498716278782, 0.6661349521602948, 0.6665495404164101, 0.6662091656909122, 0.6666762159554143, 0.6662482359450276, 0.666359437031664, 0.6665127897829487, 0.666404173112766, 0.6662693516581345, 0.6663348972403704, 0.6660453123649487, 0.666138905672605, 0.6662424350824192, 0.6663279151507067, 0.6665364295992228, 0.6660738640921277, 0.6661464995563109, 0.6661421551887079, 0.6663418860227618, 0.666130823377259, 0.6665337595158556, 0.6662888826908178, 0.6660918747733102], [0.7313273024203172, 0.6779799630392843, 0.6681282031002329, 0.6653956842066636, 0.664835651419056, 0.6646846835292987, 0.6646742455994905, 0.6646471210380098, 0.6646814470860496, 0.6646320472902326, 0.6646426942811083, 0.6645965923124285, 0.6645910980096504, 0.6645794706558114, 0.6645761274579746, 0.6645708181964818, 0.6645724728925905, 0.6645490002276292, 0.6645676253446892, 0.6645373381785492, 0.6645809518757151, 0.6646268083088434, 0.6645375659216696, 0.6645127107847982, 0.6645505615134737, 0.6645254670684018, 0.664514442877983, 0.6644830721527782, 0.6644953604954392, 0.6644751340595644, 0.6645021732173749, 0.664579130820374, 0.6644464926933175, 0.6644628537234976, 0.6645275176461063, 0.6644396523931133, 0.6644138115555492, 0.6644059161641704, 0.6644003702633416, 0.6644152376189161, 0.6644158292172561, 0.6643853383277779, 0.6643805450467921, 0.6643965235396997, 0.6643839460700306, 0.6643900604390386, 0.6645328607132186, 0.6645514137709319, 0.6643516901713699, 0.6643638441811747])\n",
      "Parameters depth:5 layer_size:32 lr:0.01 reg:0.001 gave accuracy of: (0.6194029850746269, [0.838573677142986, 0.8197625829804999, 0.8029562001814143, 0.787820411641815, 0.7743374954914007, 0.7622258068705802, 0.7513749822285247, 0.7419034527661463, 0.7334036179073893, 0.7257963512658758, 0.7191189991278252, 0.7130964469248269, 0.7077588947635031, 0.7031071933289028, 0.698934549305839, 0.6952874943948643, 0.691987249621312, 0.689100556833426, 0.6865637565383508, 0.6843270726373992, 0.6823463177743959, 0.6805275113296004, 0.6789540134301432, 0.6775617959319836, 0.6763052759271316, 0.6752044384514168, 0.6742103353359268, 0.6733233309799961, 0.6725562672318997, 0.6718393315412252, 0.6712129325501355, 0.6706651098819516, 0.6702054388614438, 0.6697519214496588, 0.6693637328544727, 0.6690160274663092, 0.6687150852683356, 0.6684210895704624, 0.668195406543374, 0.6680073970375162, 0.6677686335860974, 0.6676425805494997, 0.6674529693558162, 0.6673583694619263, 0.6672632022609484, 0.6671063205524984, 0.6669947847507431, 0.6669200272982155, 0.6668583677498479, 0.6667724519456236], [0.8304685683392766, 0.8126009764956005, 0.7964607317056229, 0.7820613268596023, 0.7690930428789623, 0.7574445534108291, 0.7472997539079012, 0.7381724306006929, 0.7299623213597198, 0.7227860573512405, 0.7162896127843145, 0.7104903157077619, 0.7054240961573017, 0.70094301451498, 0.6969366972126178, 0.6933563431697105, 0.6902229287731114, 0.6874307349546632, 0.6849990745088947, 0.6827678066581043, 0.680840635477607, 0.6790868559880043, 0.6775403583227698, 0.6761462982021161, 0.6749221335596113, 0.6738190739902098, 0.6728464987740588, 0.671970721501023, 0.67117475395772, 0.6704695233658179, 0.6698472268545805, 0.6692883656985724, 0.6687979778247093, 0.6683473444696683, 0.6679489158872348, 0.6675835411940048, 0.6672505229266722, 0.6669659160855991, 0.666726095462913, 0.6664888173786562, 0.666278029555705, 0.6661030552280482, 0.6659427374156554, 0.6657969489026425, 0.6656624585834902, 0.6655483788518763, 0.6654440564895744, 0.665348254032989, 0.6652646883210139, 0.6651809864969396])\n",
      "Parameters depth:5 layer_size:16 lr:0.001 reg:0.0001 gave accuracy of: (0.6194029850746269, [0.8410995458517239, 0.8397051495164042, 0.8383206154270247, 0.8369492332560541, 0.8355782652468159, 0.8342261621470181, 0.832885514634761, 0.831552564625381, 0.8302263961600501, 0.828900840827307, 0.8275860099212969, 0.826285087920558, 0.8249778789289719, 0.8236956020799937, 0.8224141756798506, 0.8211455801834046, 0.819880940325194, 0.818628059983096, 0.8173786521430375, 0.8161294581553108, 0.8148963823028725, 0.8136640465086329, 0.8124425371855379, 0.8112328032836259, 0.8100222188541407, 0.8088351378667622, 0.8076392131878489, 0.806460437324277, 0.8052914552046097, 0.8041344608624357, 0.8029748082475902, 0.8018246713528703, 0.8006901773310401, 0.7995606661630276, 0.7984370575083451, 0.797323855572679, 0.7962090139187469, 0.7951019705522958, 0.7940015965282838, 0.7929130987100589, 0.7918413364902985, 0.7907682926525685, 0.7897024597170489, 0.7886370166132283, 0.7875895890723447, 0.7865487470966979, 0.7855148968167475, 0.7844844737645027, 0.7834545873115368, 0.7824365660410418], [0.833531002500164, 0.8321674759708234, 0.8308117776664335, 0.8294615082776369, 0.8281268343996646, 0.8268032514337283, 0.8254892630363578, 0.8241787245914117, 0.8228701544341757, 0.8215774916001221, 0.8202910223113957, 0.8190035499743561, 0.8177361181422845, 0.8164751632000083, 0.8152204302709494, 0.8139765920923717, 0.8127407720729486, 0.8115068865356161, 0.8102748038163826, 0.8090610579768224, 0.807846511033044, 0.8066424020190737, 0.8054476709508184, 0.8042549909050785, 0.8030842862912079, 0.801908305776653, 0.8007444712653089, 0.7995925376664347, 0.798448181864041, 0.7973112032484653, 0.7961737936112419, 0.7950578541008394, 0.7939408288073184, 0.7928384333404143, 0.7917380034923553, 0.7906408136460319, 0.7895525315804268, 0.7884686295665911, 0.7873951387939169, 0.7863385352625776, 0.7852808784193067, 0.7842333712684575, 0.7831809187113349, 0.7821509210921046, 0.7811266023721268, 0.7801066530284597, 0.779093865583192, 0.7780800506250182, 0.777077684206749, 0.7760890330841292])\n",
      "Parameters depth:3 layer_size:16 lr:0.01 reg:0.0 gave accuracy of: (0.6194029850746269, [0.8714101098015254, 0.8260485328330389, 0.78964499910725, 0.7607141456011894, 0.739083162780797, 0.7236567151436245, 0.712056610669296, 0.7022857955771362, 0.6939961830722451, 0.6871719982381541, 0.6815247875066226, 0.6768640434883703, 0.6730816086343289, 0.669917547482323, 0.6673582034035435, 0.6652608878388903, 0.6635191550815436, 0.6620550536731433, 0.6607829477229553, 0.6597150390970187, 0.658812269036962, 0.6579624501843119, 0.6572633493529286, 0.6565179122486392, 0.6559532036712021, 0.655337118094632, 0.6548323095868411, 0.6543268305464811, 0.6537417615105643, 0.6532178581784549, 0.6527677171296457, 0.6521996451022603, 0.6517113803872344, 0.6511169646028798, 0.650556187333645, 0.6499885945842949, 0.6494321987682479, 0.6487770900228694, 0.6481742415591937, 0.6475460015168436, 0.6469380050858229, 0.6462038612901141, 0.6455262403349581, 0.6447939834947473, 0.6441188160935355, 0.6434536493596187, 0.6426322532613494, 0.6418501418994313, 0.6410612322222762, 0.6402021132340677], [0.8484571531637392, 0.8083425778061596, 0.7763598703626376, 0.7521105026131245, 0.7341289546952319, 0.721275410545406, 0.7106069130684013, 0.7016463884666785, 0.694064701671031, 0.6878433289812572, 0.6827359484202826, 0.6785245003984935, 0.6751319846110557, 0.6723958387303708, 0.6701819193896963, 0.6683173224107543, 0.6668435175027421, 0.6656781968785755, 0.6646518947473213, 0.6637813431113514, 0.6631130647303453, 0.6624983646976415, 0.6619448795247433, 0.6614931910785277, 0.6610868528707704, 0.6607364620735396, 0.6603999974122688, 0.6600700172025766, 0.6597691560859111, 0.6594758113818382, 0.6591847040759984, 0.658888048200465, 0.6585827478721961, 0.6582811136743916, 0.6579578919197197, 0.6576291660764324, 0.6572806666146463, 0.6569244870498999, 0.6565639430017614, 0.6561923943348785, 0.6558084986103114, 0.6553983510430179, 0.65496513291971, 0.6545157050018879, 0.6540648092084856, 0.6535796096075827, 0.653079482156839, 0.6525583080391386, 0.6520302713806949, 0.65147719187523])\n",
      "Parameters depth:3 layer_size:16 lr:0.01 reg:0.0001 gave accuracy of: (0.7014925373134329, [0.7794168893065762, 0.760228592228228, 0.7426562924996077, 0.7262064753151948, 0.7123369944615282, 0.7010742950313472, 0.692011476507905, 0.6845526044875816, 0.6785479503704661, 0.6735949135991982, 0.6693616776359286, 0.6658829087625249, 0.6628223414307699, 0.660163919393421, 0.6577391535476775, 0.655657548491832, 0.6536970569246512, 0.6519079917015771, 0.6502843059825771, 0.6485904747302812, 0.6469892887017213, 0.6454112120317185, 0.6438265622370781, 0.6422297418353737, 0.6406489985464744, 0.6390306248060148, 0.6372911581275013, 0.6355814804646581, 0.6337509196217183, 0.632014939933031, 0.6301336559310772, 0.6281764120690259, 0.6263047763819424, 0.6242585647531356, 0.6222900612036177, 0.6200556929076836, 0.6178748998175839, 0.6157136273667551, 0.6132449633694073, 0.6110388988547785, 0.6083725223138121, 0.6058609287206531, 0.603257184693174, 0.6005971231737729, 0.5979208998982468, 0.5952067498014342, 0.5923452597785658, 0.5894660738689267, 0.5865053520334916, 0.5833573231923848], [0.7664426556274072, 0.7474870601696755, 0.7290463847900505, 0.7124573410446964, 0.6992309814068809, 0.6886502833508733, 0.6798345660095784, 0.6727207783442825, 0.6668247847414729, 0.6618886385391007, 0.6577582430483689, 0.6541597122576699, 0.651045970952333, 0.6481985983563893, 0.6457138461853141, 0.6435025441112803, 0.6414238054360917, 0.6395061585440565, 0.6376353867018401, 0.6359232993268255, 0.6341947993235801, 0.6324969966020157, 0.6307510822566588, 0.6290035274491381, 0.6272203459668515, 0.6254203203898757, 0.623599140501734, 0.621731629122549, 0.6198221542941991, 0.6178285461753162, 0.6157984422213996, 0.6137514052106373, 0.6116605054086713, 0.6095222466027559, 0.6073112114151912, 0.6050255609982049, 0.6026843990852584, 0.6002763118316878, 0.5978484064785402, 0.5952894892265548, 0.5926900764009846, 0.5900126437642681, 0.5872870007557656, 0.584482484789037, 0.5816212990390721, 0.5786431823203813, 0.5756150137132673, 0.5725412435496031, 0.5694012966618609, 0.5661567978894533])\n",
      "Parameters depth:3 layer_size:16 lr:0.1 reg:0.0 gave accuracy of: (0.7611940298507462, [0.7020197920156753, 0.6588680781177989, 0.6501765590520328, 0.6411591995817509, 0.628582031440231, 0.6128077638511457, 0.590151343903107, 0.5619501630570174, 0.5333475537076494, 0.5086016564419594, 0.49122454503568347, 0.47746403017321226, 0.4728382852622351, 0.4674477536265727, 0.466918546465303, 0.46192380033994446, 0.4585831971590554, 0.4559414468636758, 0.45812249597029137, 0.4548574059296158, 0.456448121894461, 0.4520372731052585, 0.4511447304384869, 0.45121614093667134, 0.446859500052277, 0.44693174544854714, 0.444903721188932, 0.44267051790003104, 0.44130301436155916, 0.4533227233307207, 0.44017680680263627, 0.4375067747725836, 0.43751298511201514, 0.4361235968266642, 0.4390860642435686, 0.43629480038167934, 0.438238737723314, 0.4363197189419871, 0.4345448351756742, 0.4317613155476483, 0.4338101502138841, 0.436410553034892, 0.4300894923852646, 0.4318265356664771, 0.42906359853801196, 0.42982149226504873, 0.4273126993421834, 0.42861175978042015, 0.42751659553306104, 0.4292814749707634], [0.6675208477831599, 0.6541871561932919, 0.6471574448827487, 0.6378775559254547, 0.624438658579072, 0.6054106016657246, 0.5818948861378342, 0.5539887049304906, 0.5285689581685992, 0.5066994562077878, 0.4942091801273289, 0.48616445598317615, 0.48441707465186046, 0.48073293913656207, 0.4812995542341204, 0.4653971150739869, 0.4655766620564817, 0.467559194386895, 0.46762369017102823, 0.46097373695515875, 0.4637196019514283, 0.45558325924090487, 0.4588629167471359, 0.4568978183305086, 0.4627002255240483, 0.4541091776605862, 0.4513498606966503, 0.44142781798519304, 0.440204082140282, 0.4447354496414982, 0.4580552782585372, 0.4422178739932046, 0.44086753788279065, 0.4452873833143889, 0.44257954074375666, 0.4386031725513401, 0.43496838167532165, 0.4446143418995302, 0.45297461926047483, 0.4349784966725022, 0.43848365100462044, 0.44714401284260535, 0.4390169969245569, 0.4418646577578872, 0.4334541541426929, 0.43529336221182524, 0.42997406845662134, 0.4305919720165765, 0.426130159577327, 0.43653963839829857])\n",
      "Parameters depth:3 layer_size:16 lr:0.1 reg:0.0001 gave accuracy of: (0.7761194029850746, [0.6899625541669374, 0.6733047692117476, 0.6684068796499245, 0.6672159545172789, 0.6667559220894798, 0.666693597047773, 0.666578527800788, 0.6663272795777969, 0.6664981976682948, 0.6663683022974032, 0.666324850353886, 0.666480151003859, 0.6666471282588601, 0.6664852425948159, 0.6663712030830282, 0.6664427458216367, 0.6664921298052234, 0.6665222230644176, 0.6664016838905203, 0.6665209750675619, 0.6663428959947281, 0.6664509760656319, 0.6662567989356925, 0.6665816365333971, 0.6660728271917749, 0.6659883639456574, 0.6651043695849188, 0.6651101847778381, 0.6643895543078293, 0.6642221770639306, 0.6633100375789003, 0.6623360701249802, 0.6612774380132104, 0.6601276629982096, 0.6585677516507662, 0.6564987467963598, 0.6535839914015766, 0.6499752866072258, 0.6456324400643534, 0.6380657604065093, 0.6277075878380154, 0.6135915721738354, 0.595221196172102, 0.5728857906995393, 0.550118770947387, 0.528896318716606, 0.5121726957463525, 0.4978886012042057, 0.4887025202753679, 0.47720454312378696], [0.6770975349554375, 0.6684011888148179, 0.6658385093532392, 0.6650463155846098, 0.6646757259297726, 0.6645095339461938, 0.6643856247859214, 0.6643725375630962, 0.6643658725183401, 0.6643780069564705, 0.6643803057385914, 0.6643957388934805, 0.6643936358281036, 0.6643797283741966, 0.6643729476786372, 0.6643791492305585, 0.6643547584761434, 0.664345726148406, 0.6643894350350793, 0.6643420724726435, 0.6643098290286847, 0.6642576536135887, 0.6641543151727364, 0.6640568357795033, 0.663858517782012, 0.663334044947553, 0.6629862687480983, 0.6626218557357788, 0.6622353854464061, 0.6615469144351447, 0.660694601820476, 0.659662127494812, 0.6584719463960448, 0.6569221562414027, 0.6549542706404159, 0.6524459007960647, 0.6490339636802673, 0.6446423503889966, 0.6383277969573861, 0.6290691228055242, 0.6163512664054757, 0.5986563883610626, 0.5757113045720912, 0.5502887706258404, 0.5261601307498875, 0.5072928862785225, 0.48970801794706886, 0.475751107308402, 0.4705759042234563, 0.4602771014419954])\n",
      "Parameters depth:5 layer_size:32 lr:0.1 reg:0.001 gave accuracy of: (0.7835820895522388, [0.7264295191242012, 0.6789298750450306, 0.6688125306737943, 0.6670564391811427, 0.6666133231341917, 0.6662026237465116, 0.6660165475728175, 0.6661528575688088, 0.6663465725855909, 0.6656095388700971, 0.6656383790932054, 0.6659039336120122, 0.6656452081949896, 0.6654912410513099, 0.6664180800495878, 0.6651462653511582, 0.6651846790880634, 0.6649298786802053, 0.6648723579145958, 0.6651318164608753, 0.665158858151228, 0.6644771596714559, 0.6639422390073577, 0.6636737403970413, 0.663807275036997, 0.6633246212685912, 0.6632275904972929, 0.6624680410288126, 0.6620636151677866, 0.6615797582831692, 0.6611294903874869, 0.6602998345184831, 0.6594574540420441, 0.6575417772151992, 0.6560810446109293, 0.6541181827158405, 0.6506238691557982, 0.6469863569720733, 0.6417001251972808, 0.6315685014586153, 0.6199568246283336, 0.6008733037755858, 0.5751436411783276, 0.5436000033445371, 0.5196982896942128, 0.5034767481420912, 0.4901472345840978, 0.48164610661162727, 0.4780573449251359, 0.4726552666414682], [0.6900181485645807, 0.6696228046915425, 0.6651472431510242, 0.6639928613136064, 0.6640239660419635, 0.6637060579968922, 0.6635280989888889, 0.6633942616519644, 0.6635765130840131, 0.6633366764481388, 0.6632527335366206, 0.6629970812085849, 0.6628952337734735, 0.6627793578959223, 0.6626671401422415, 0.662626974618257, 0.6625318171373055, 0.6623408678752273, 0.6620981657682959, 0.6619474033811199, 0.661775653931632, 0.6616829945080316, 0.6612936480721431, 0.6609887445150916, 0.6609157261563771, 0.6606885265948167, 0.6599933513954505, 0.65962240144388, 0.6589597356853201, 0.6584189783281355, 0.6576821599433671, 0.6568495675699034, 0.6554641803698753, 0.654177851641356, 0.6520796222473259, 0.6495390463231215, 0.6462170374927236, 0.6414305194100337, 0.6344143410227192, 0.6250556449391949, 0.6094981013838925, 0.589133675418683, 0.5559224619794247, 0.5233053458270742, 0.5010088602108742, 0.4854068622660281, 0.4765285618269621, 0.4651317525265822, 0.4603640846352079, 0.45835247769284604])\n",
      "Parameters depth:3 layer_size:16 lr:0.1 reg:0.001 gave accuracy of: (0.7910447761194029, [0.6743622885197598, 0.667833826264743, 0.6655640983203601, 0.6643609727389589, 0.6632520306850519, 0.662375785321824, 0.6605861917669581, 0.6583665100712442, 0.655612214395833, 0.6523872806027512, 0.6475978162991008, 0.6417986186838843, 0.6331811633891127, 0.6216164680106794, 0.6040533262955781, 0.579926191579398, 0.549567587388239, 0.5200973673178624, 0.49426211883243826, 0.4772153280212826, 0.46687659003145626, 0.4623043187936987, 0.4608567798783316, 0.4578612925118153, 0.4560017418042514, 0.4516133073928964, 0.4480909805159273, 0.4507756030858744, 0.4465095194516755, 0.44360123265687196, 0.4419517258829296, 0.4405219667496423, 0.44249653536703343, 0.44257652381609736, 0.43967874795001594, 0.4414262688537885, 0.43609254367285394, 0.43805579268318184, 0.43634570888987934, 0.43647308712591426, 0.4373117310131557, 0.43732327372426244, 0.43687302590676313, 0.4330728274512952, 0.4331107452570841, 0.43047060901139184, 0.4308986931133774, 0.43356677295352225, 0.4345577758401042, 0.43292743290431274], [0.6698030046562651, 0.6671239075376026, 0.6661669754270297, 0.665510900874636, 0.6649240655685539, 0.6642628409969273, 0.6634916805509311, 0.662460836011972, 0.661037266254425, 0.6589989066123962, 0.6562824854210242, 0.6523477559659019, 0.6458863704951842, 0.6354478339650738, 0.6177669149726185, 0.5920829986458394, 0.5614928603172302, 0.5273584260869382, 0.4944751556239911, 0.47165619526336444, 0.46474203422888, 0.44924489775700355, 0.4452709697965366, 0.44263321339194456, 0.43878543287960453, 0.43901151418685913, 0.43379771264631356, 0.43983564092152155, 0.43873377077615083, 0.4301491949095655, 0.427270017453094, 0.4479324168233729, 0.4416796627329357, 0.4276022626392877, 0.43355348839688657, 0.4342307617415243, 0.4275469379638558, 0.4417293498765177, 0.42697359999613976, 0.4345281302039303, 0.4340691957900773, 0.4356454957776995, 0.4344550130972222, 0.4350739699691089, 0.4371152529075964, 0.43948368794882475, 0.44392225279736874, 0.45154860215400583, 0.45537696400685096, 0.4387298084017056])\n",
      "Parameters depth:3 layer_size:32 lr:0.1 reg:0.0001 gave accuracy of: (0.8134328358208955, [0.6772395386563582, 0.66398860842895, 0.657562393572088, 0.6521487433655259, 0.6449929845065391, 0.6353647227016433, 0.6212660930115764, 0.6001217393610563, 0.570908228818775, 0.5351280341690093, 0.5026318921831829, 0.4762831612575007, 0.46272316177423595, 0.45397822832494306, 0.44737425052820456, 0.44329017719630365, 0.4402692341584038, 0.4426921734800427, 0.43727527710374153, 0.4331167184771131, 0.44043195031120724, 0.4347924906637426, 0.43227271391189553, 0.4288662103948379, 0.4299167288341799, 0.4295551578466297, 0.42820759052644475, 0.4334788294103061, 0.42793617837495185, 0.42904688849001926, 0.42286634102680254, 0.42348220157024885, 0.4300562174033615, 0.42920112003580896, 0.42119767049344714, 0.4227914074768006, 0.42606555994309714, 0.4225836753294049, 0.4204642114031425, 0.41951195858271306, 0.41808501689090755, 0.41909861438655477, 0.41715284142657977, 0.4158601077812351, 0.42495473577607734, 0.4183948231341817, 0.41388217823351076, 0.4174554877111115, 0.41664065339921175, 0.4135223905429185], [0.6666077580024947, 0.6561478287426393, 0.6501175040629372, 0.6430085461531112, 0.6336760449765334, 0.6205853748677382, 0.6016678979147726, 0.5746298254425846, 0.5392479095886002, 0.49900114981096183, 0.4679443729457571, 0.44796311588429694, 0.430788217195824, 0.4221385388231989, 0.42339401814474986, 0.4122258006636776, 0.40743615734043404, 0.4026516053214002, 0.4021755741603339, 0.4008988577928116, 0.4042800727175243, 0.4032262323507622, 0.3999013304710388, 0.3985125404685291, 0.3914608955383301, 0.40258500558226856, 0.40225354860078044, 0.3900547979482964, 0.393206495847275, 0.38748051070455297, 0.3882996955914284, 0.39948809591691886, 0.39128106298731335, 0.3950566346965619, 0.38779468678716406, 0.38853327196035814, 0.38292818727777966, 0.3927364233714431, 0.38075097016434173, 0.38332175585760997, 0.37823042940737595, 0.38034140796803717, 0.3720733336548307, 0.3851568947977094, 0.37352691568545443, 0.37124339413287033, 0.3719596613698931, 0.36679415916329, 0.3702612145623164, 0.38102138487260734])\n",
      "Parameters depth:3 layer_size:32 lr:0.1 reg:0.0 gave accuracy of: (0.8134328358208955, [0.6994077871938678, 0.6722489330066242, 0.664108673600256, 0.6598060146820592, 0.6548336649035525, 0.6489641129419385, 0.641061811182584, 0.6296789119391649, 0.6141405159132641, 0.5925501099980807, 0.5606228938348384, 0.5252715712966818, 0.49457998359219085, 0.47421999954799365, 0.46389886756554305, 0.45743595388480507, 0.4538821574876299, 0.45263934261417765, 0.4494328004365868, 0.4451038719325903, 0.44339369003177476, 0.4434031156756604, 0.43978212157675267, 0.44345262453767076, 0.43530928816946524, 0.4357747991853535, 0.43347843040563316, 0.42985179103034965, 0.4297814813283822, 0.42928953285733806, 0.4287976229285312, 0.4279533127812445, 0.42596510828249995, 0.4305248277426711, 0.42798831696711886, 0.42381097949165336, 0.4251771112965467, 0.42099401071333037, 0.4230326353873728, 0.42036586641635415, 0.4229273717737261, 0.4218467231470811, 0.421390655884812, 0.4161519846796517, 0.41714269820418665, 0.417397834980661, 0.4203214536727341, 0.421350632271332, 0.4253971884556144, 0.41815411288640614], [0.6767563997809567, 0.663741034358295, 0.6593227991417273, 0.6547908418214143, 0.6502370069276041, 0.6435640294160416, 0.6344462615340504, 0.6219612591302217, 0.6030890986100951, 0.5759999529639287, 0.542078590215142, 0.503424750335181, 0.4812997624055663, 0.4673690858171947, 0.45517866380179106, 0.4477018340310054, 0.4441343376885599, 0.4519983298742949, 0.45231593900652073, 0.4373528512556161, 0.43983308859725495, 0.4395561191573072, 0.4511060216533604, 0.44067644806050543, 0.43868524280946647, 0.42916339635849, 0.4258733898846071, 0.43089847422357813, 0.42518093425836134, 0.4235987423071221, 0.4316797149715139, 0.4317757273787883, 0.4212631209572749, 0.4180317458821766, 0.416897114533097, 0.4237406280503344, 0.42479725026372656, 0.4105991979143513, 0.41166537466333875, 0.4222799806452509, 0.4229839693254499, 0.41170527952820507, 0.4158703791561411, 0.4002565563614689, 0.39674510884640823, 0.4082748071471257, 0.40465303321382895, 0.3975757831957803, 0.4011497026059165, 0.39981299727710323])\n",
      "Parameters depth:3 layer_size:32 lr:0.1 reg:0.001 gave accuracy of: (0.835820895522388, [0.7268397040379725, 0.6823292401381811, 0.6681328876487802, 0.6628450966259289, 0.6591411441603929, 0.6566392160469822, 0.6519650435825635, 0.6467929283252953, 0.6400638701421266, 0.6299350723092748, 0.6158999870758863, 0.5978266673957341, 0.5745264995680776, 0.5476230902589927, 0.5226766091514295, 0.5008073036547853, 0.4835771898612321, 0.47023407786179094, 0.4600223950854696, 0.4540567153983576, 0.44702041511334073, 0.44436127561559136, 0.4435672447420017, 0.4390544430346596, 0.43604636621443726, 0.436619483456114, 0.43308669025548385, 0.4343987650568923, 0.43022018119869965, 0.42923114424180164, 0.42797325191283636, 0.42756407098694554, 0.42753592184701716, 0.4250746692974942, 0.4245292841994463, 0.4226149842241481, 0.42154647132364576, 0.423107267567787, 0.4202296995659958, 0.4189508353388294, 0.41902053726239125, 0.4186662542615258, 0.41410446115812505, 0.41909707041366256, 0.41294682644002506, 0.41716866921559664, 0.4110725473617468, 0.4097334814985016, 0.4110064063629669, 0.4119459542604545], [0.6913306997783148, 0.6684731342899266, 0.6600109854740883, 0.65607304982285, 0.6529029474329593, 0.6490660256414271, 0.6441610473305431, 0.6379410437683561, 0.6291899592129152, 0.6172098232739007, 0.600279876545294, 0.5781244199667404, 0.5523647826109359, 0.5213513792450748, 0.4982828435613148, 0.47427229916871483, 0.45735435610386865, 0.4460412788746962, 0.4388073958567719, 0.43683750149029404, 0.4337751642981572, 0.43011084332394955, 0.43422868180630814, 0.42838111831181086, 0.4243147818010245, 0.41436903334375635, 0.41199202590913914, 0.4083492835955833, 0.4097815583001322, 0.40729685950635086, 0.4035771916161722, 0.40205392552845515, 0.39673931296192, 0.3990318641733767, 0.3871709312965621, 0.3898492028464132, 0.3881645024712406, 0.3847060105693874, 0.38501219073338294, 0.38172551144414874, 0.3787293389661988, 0.37736423780669026, 0.38146771690738734, 0.37516760737148686, 0.37026981097548756, 0.3672811602478597, 0.36842098253876415, 0.374280745413766, 0.36663219199251773, 0.3694079616176548])\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'depth': [3, 5], \n",
    "    'layer_size': [16, 32], \n",
    "    'lr': [.001, .01, .1], \n",
    "    'reg': [.00, 1e-4, 1e-3]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for depth, layer_size, lr, reg in itertools.product(\n",
    "        param_distributions['depth'],\n",
    "        param_distributions['layer_size'],\n",
    "        param_distributions['lr'],\n",
    "        param_distributions['reg']): \n",
    "    \n",
    "    model = MLP_Network(8, layer_size, 2, depth, lr, reg)\n",
    "    model.to(device)\n",
    "\n",
    "    acc = train(model, train_loader, val_loader, 50)\n",
    "\n",
    "    result = namedtuple('result', ['acc', 'depth', 'layer_size', 'lr', 'reg'])\n",
    "\n",
    "    trial = result(acc, depth, layer_size, lr, reg)\n",
    "    results.append(trial)    \n",
    "\n",
    "results.sort(key=lambda x: x[0])\n",
    "for trial in results: \n",
    "    print(f\"Parameters depth:{trial.depth} layer_size:{trial.layer_size} lr:{trial.lr} reg:{trial.reg} gave accuracy of: {trial.acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bc903eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "027b3ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34851545 0.66777194 0.8510151  0.91128266 0.94938165 0.9765948\n",
      " 0.9950384  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# TASK 3\n",
    "\n",
    "X_train = train_dataset.X.numpy()\n",
    "X_val = val_dataset.X.numpy()\n",
    "X_test = test_dataset.X.numpy()\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "\n",
    "cumulative_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "print(cumulative_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d14ebcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 4 # 4 components gives 91.1% variance\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train) \n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b167aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig:  8\n",
      "new:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"orig: \", X_val.shape[1])\n",
    "print(\"new: \", X_val_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0b7d6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicPCADataset(Dataset): \n",
    "    def __init__(self, X, y, test=False): \n",
    "        if (test == True): \n",
    "            self.X = torch.tensor(X, dtype=torch.float32)\n",
    "            self.y = None\n",
    "        else: \n",
    "            self.X = torch.tensor(X, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        if (self.y is not None):\n",
    "            return self.X[idx], self.y[idx]\n",
    "\n",
    "        return self.X[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5ed1a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zebul\\AppData\\Local\\Temp\\ipykernel_3944\\3808468872.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_pca = TitanicPCADataset(X_train_pca, train_dataset.y, False)\n",
    "val_dataset_pca = TitanicPCADataset(X_val_pca, val_dataset.y, False)\n",
    "test_dataset_pca = TitanicPCADataset(X_test_pca, test_dataset.y, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a3f3424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pca = DataLoader(\n",
    "    # these variable primarily affect efficiency at fetching data\n",
    "    train_dataset_pca,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader_pca = DataLoader(\n",
    "    val_dataset_pca,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader_pca = DataLoader(\n",
    "    test_dataset_pca,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e5db404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_Network(\n",
      "  (model): Sequential(\n",
      "    (layer_0): Linear(in_features=4, out_features=16, bias=True)\n",
      "    (activation_0): ReLU()\n",
      "    (layer_1): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (activation_1): ReLU()\n",
      "    (layer_2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (activation_2): ReLU()\n",
      "    (output_layer): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      "  (loss): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_nn_pca = MLP_Network(input_size=4, hidden_size=16, num_classes=2, network_depth=3, learning_rate=0.1, regularization=0.0)\n",
    "\n",
    "model_nn_pca.to(device)\n",
    "\n",
    "print(model_nn_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5ce05bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, train_losses, val_losses = train(model_nn_pca, train_loader_pca, val_loader_pca, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7d570254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283582089552238\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "336ff29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "693c1d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=45)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">45</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=45)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_classifier = LogisticRegression(max_iter=1000, random_state=45)\n",
    "log_classifier.fit(train_dataset_pca.X, train_dataset_pca.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8a79313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8059701492537313\n",
      "Validation Log Loss (Binary Cross Entropy): 0.47358998692708226\n",
      "Confusion Matrix:\n",
      " [[77  6]\n",
      " [20 31]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions from SKlearn model\n",
    "y_val_pred = log_classifier.predict(val_dataset_pca.X)\n",
    "y_val_probs = log_classifier.predict_proba(val_dataset_pca.X)[:, 1]  # probability of \"Survived\" \n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(val_dataset_pca.y, y_val_pred)\n",
    "loss = log_loss(val_dataset_pca.y, y_val_probs)\n",
    "cm = confusion_matrix(val_dataset_pca.y, y_val_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", acc)\n",
    "print(\"Validation Log Loss (Binary Cross Entropy):\", loss)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3234710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HW2 TASK 3 ###\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c7f4d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# param_distributions contains all of the options for each parameter we will experiment with \n",
    "param_distributions = {\n",
    "    'model__n_estimators': [10, 50, 100, 200, 400, 800],\n",
    "    'model__max_depth': [None, 5, 10, 20, 40],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4],\n",
    "    'model__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6f30ca87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'model__n_estimators': 800, 'model__min_samples_split': 2, 'model__min_samples_leaf': 2, 'model__max_depth': 5, 'model__bootstrap': True}\n",
      "Best cross-validation accuracy: 0.8057772743116068\n"
     ]
    }
   ],
   "source": [
    "# randomized search will allow us to try all permutations of these parameters \n",
    "search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,              # number of random combinations to try\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(train_dataset_pca.X, train_dataset_pca.y)\n",
    "\n",
    "# saving the best performing model for future use \n",
    "best_rf = search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "71a8fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_dataset_pca.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a82addd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Build submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": y_test_pred_rf.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv(\"best_rf_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b84405c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_logreg = log_classifier.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": y_test_pred_logreg.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv(\"best_logreg_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "989444dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6662, -0.5506,  0.1857, -0.2445],\n",
      "        [-0.5982,  0.1076,  1.3392,  0.6941],\n",
      "        [-2.1478,  0.3842,  1.4947, -0.1149],\n",
      "        ...,\n",
      "        [-0.8814, -0.4091,  0.3780, -0.2907],\n",
      "        [-0.3293, -0.6926, -0.1429, -0.3286],\n",
      "        [ 0.3554, -0.1496,  0.2511, -0.3328]])\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b6aba8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "[]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[305]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m y_test_pred_mlp = \u001b[38;5;28meval\u001b[39m(model_nn_pca, test_loader_pca)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(y_test_pred_mlp)\n\u001b[32m      5\u001b[39m submission = pd.DataFrame({\n\u001b[32m      6\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33mPassengerId\u001b[39m\u001b[33m\"\u001b[39m: passenger_ids,\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33mSurvived\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43my_test_pred_mlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      8\u001b[39m  })\n\u001b[32m     10\u001b[39m submission.to_csv(\u001b[33m\"\u001b[39m\u001b[33mbest_mlp_submission.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "y_test_pred_mlp = eval(model_nn_pca, test_loader_pca)\n",
    "\n",
    "print(y_test_pred_mlp)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "     \"PassengerId\": passenger_ids,\n",
    "     \"Survived\": y_test_pred_mlp.astype(int)\n",
    " })\n",
    "\n",
    "submission.to_csv(\"best_mlp_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
